{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**when sampling from k-dpp**\n",
    "\n",
    "We shall sample until one of the following is met:\n",
    "\n",
    "*  Number of samples is complete based on PCA on kernel (choice of k)\n",
    "*  Stopping criterion based on wilcoxon non-parametric test (early stopping). Using library: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html\n",
    "\n",
    "For speed we will demo the Nystroem kernel\n",
    "\n",
    "Based on the following notebook: https://github.com/chappers/Context-driven-constraints-for-gradient-boosted-models/blob/master/autoML/streaming/dpp-groupfs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression, make_classification\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from dpp import sample_dpp, decompose_kernel, sample_conditional_dpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90966213190221712"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(np.random.normal(size=(100,)), np.random.normal(size=(100,))).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_regression()\n",
    "pdf = pd.DataFrame(X)\n",
    "pdf.columns = ['c{}'.format(x) for x in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = pdf[['c{}'.format(x) for x in range(50, 100)]]\n",
    "X2 = pdf[['c{}'.format(x) for x in range(50)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 13]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx for idx, x in enumerate(pdf.columns) if x in ['c0', 'c13']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(X):\n",
    "    mm = MinMaxScaler()\n",
    "    X_mm = mm.fit_transform(X)\n",
    "    Dpq = euclidean_distances(X_mm)\n",
    "    D_bar = np.mean([x for x in np.triu(Dpq).flatten() if x != 0])\n",
    "    alpha = -np.log(0.5)/D_bar\n",
    "    sim_pq = np.exp(-alpha * Dpq)\n",
    "    log_sim_pq = np.log(sim_pq)\n",
    "    entropy = -2*np.sum(np.triu(sim_pq*log_sim_pq + ((1-sim_pq)*np.log((1-sim_pq))), 1))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wilcoxon_group(X, f):\n",
    "    # X is a matrix, f is a single vector\n",
    "    if len(X.shape) == 1:\n",
    "        return wilcoxon(X, f).pvalue\n",
    "    # now we shall perform and check each one...and return only the lowest pvalue\n",
    "    return np.min([wilcoxon(x, f) for x in X.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implement DPP version that is similar to what is done above\n",
    "\n",
    "\n",
    "sketch of solution\n",
    "------------------\n",
    "\n",
    "DPP requires a known number of parameters to check at each partial fit!\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class DPPRegressor(SGDRegressor):\n",
    "    def __init__(self, loss=\"squared_loss\", penalty=\"l2\", alpha=0.0001,\n",
    "                 l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None,\n",
    "                 shuffle=True, verbose=0, epsilon=0.1,\n",
    "                 random_state=None, learning_rate=\"invscaling\", eta0=0.01,\n",
    "                 power_t=0.25, warm_start=False, average=False, n_iter=None,\n",
    "                 intragroup_alpha=0.05, intergroup_thres=None):\n",
    "        super(DPPRegressor, self).__init__(loss=loss, penalty=penalty,\n",
    "                                           alpha=alpha, l1_ratio=l1_ratio,\n",
    "                                           fit_intercept=fit_intercept,\n",
    "                                           max_iter=max_iter, tol=tol,\n",
    "                                           shuffle=shuffle,\n",
    "                                           verbose=verbose,\n",
    "                                           epsilon=epsilon,\n",
    "                                           random_state=random_state,\n",
    "                                           learning_rate=learning_rate,\n",
    "                                           eta0=eta0, power_t=power_t,\n",
    "                                           warm_start=warm_start,\n",
    "                                           average=average, n_iter=n_iter)\n",
    "        self.coef_info = {'cols': [], 'coef':[], 'excluded_cols': []}\n",
    "        self.seen_cols = []\n",
    "        self.base_shape = None\n",
    "        self.intragroup_alpha = intragroup_alpha\n",
    "        self.intergroup_thres = intergroup_thres if intergroup_thres is not None else epsilon\n",
    "    \n",
    "    def _dpp_estimate_k(self, L):\n",
    "        \"\"\"\n",
    "        L is the input kernel\n",
    "        \"\"\"\n",
    "        pca = PCA(n_components=None)\n",
    "        pca.fit(L)\n",
    "        return np.min(np.argwhere(np.cumsum(pca.explained_variance_ratio_) > \n",
    "                                  (1-self.intragroup_alpha)))\n",
    "        \n",
    "    \n",
    "    def add_column_exclusion(self, cols):\n",
    "        self.coef_info['excluded_cols'] = list(self.coef_info['excluded_cols']) + list(cols)\n",
    "        \n",
    "    def _fit_columns(self, X_, return_x=True, transform_only=False):\n",
    "        \"\"\"\n",
    "        Method filter through \"unselected\" columns. The goal of this \n",
    "        method is to filter any uninformative columns.\n",
    "        \n",
    "        This will be selected based on index only?\n",
    "        \n",
    "        If return_x is false, it will only return the boolean mask.\n",
    "        \"\"\"\n",
    "        X = X_[X_.columns.difference(self.coef_info['excluded_cols'])]\n",
    "        \n",
    "        # order the columns correctly...\n",
    "        col_order = self.coef_info['cols'] + list([x for x in X.columns if x not in self.coef_info['cols']])\n",
    "        X = X[col_order]\n",
    "        return X\n",
    "\n",
    "    def _reg_penalty(self, X):\n",
    "        col_coef = [(col, coef) for col, coef in zip(X.columns.tolist(), self.coef_) if np.abs(coef) >= self.intergroup_thres]\n",
    "        self.coef_info['cols'] = [x for x, _ in col_coef]\n",
    "        self.coef_info['coef'] = [x for _, x in col_coef]\n",
    "        self.coef_info['excluded_cols'] = [x for x in self.seen_cols if x not in self.coef_info['cols']]\n",
    "        self.coef_ = np.array(self.coef_info['coef'])  \n",
    "    \n",
    "    def _dpp_sel(self, X_, y=None):\n",
    "        \"\"\"\n",
    "        DPP only relies on X. \n",
    "        \n",
    "        We will condition the sampling based on:\n",
    "        *  `self.coef_info['cols']`\n",
    "        \n",
    "        After sampling it will go ahead and then perform grouped wilcoxon selection.\n",
    "        \"\"\"\n",
    "        X = np.array(X_)\n",
    "        if X.shape[0] < 1000:\n",
    "            feat_dist = rbf_kernel(X.T)\n",
    "        else:\n",
    "            feat_dist = Nystroem().fit_transform(X.T)\n",
    "        k = self._dpp_estimate_k(feat_dist) - len(self.coef_info['cols'])\n",
    "                \n",
    "        if len(self.coef_info['cols']) == 0:\n",
    "            feat_index = sample_dpp(decompose_kernel(feat_dist), k=k)\n",
    "        else:\n",
    "            cols_to_index = [idx for idx, x in enumerate(X_.columns) if x in self.coef_info['cols']]\n",
    "            feat_index = sample_conditional_dpp(feat_dist, cols_to_index, k=k)\n",
    "        \n",
    "        # select features using entropy measure\n",
    "        # how can we order features from most to least relevant first?\n",
    "        # we chould do it using f test? Or otherwise - presume DPP selects best one first\n",
    "        \"\"\"\n",
    "        feat_entropy = []\n",
    "        excl_entropy = []\n",
    "        X_sel = X[:, feat_index]\n",
    "        \n",
    "        for idx, feat in enumerate(X_sel.T):\n",
    "            if len(feat_entropy) == 0:\n",
    "                feat_entropy.append(idx)\n",
    "                continue\n",
    "            if entropy(X_sel[:, feat_entropy]) > entropy(X_sel[:, feat_entropy+[idx]]):\n",
    "                feat_entropy.append(idx)\n",
    "            else:\n",
    "                excl_entropy.append(idx)\n",
    "        \"\"\"\n",
    "        # iterate over feat_index to determine \n",
    "        # information on wilcoxon test\n",
    "        # as the feat index are already \"ordered\" as that is how DPP would\n",
    "        # perform the sampling - we will do the single pass in the same\n",
    "        # way it was approached in the OGFS\n",
    "        feat_check = []\n",
    "        excl_check = []\n",
    "        X_sel = X[:, feat_index]\n",
    "        \n",
    "        for idx, feat in enumerate(X_sel.T):\n",
    "            if len(feat_check) == 0:\n",
    "                feat_check.append(idx)\n",
    "                continue\n",
    "            if wilcoxon_group(X_sel[:, feat_check], feat) >= self.intragroup_alpha:\n",
    "                feat_check.append(idx)\n",
    "            else:\n",
    "                excl_check.append(idx)\n",
    "        index_to_col = [col for idx, col in enumerate(X_.columns) if idx in feat_check]\n",
    "        self.coef_info['cols'] = list(set(self.coef_info['cols'] + index_to_col))\n",
    "        col_rem = X_.columns.difference(self.coef_info['cols'])\n",
    "        self.add_column_exclusion(col_rem)        \n",
    "        \n",
    "    def fit(self, X, y, coef_init=None, intercept_init=None,\n",
    "            sample_weight=None):\n",
    "        self.seen_cols = list(set(self.seen_cols + X.columns.tolist()))\n",
    "        \n",
    "        # TODO: add DPP selection\n",
    "        self.coef_info = {'cols': [], 'coef':[], 'excluded_cols': []}\n",
    "        self._dpp_sel(X, y)\n",
    "        X = self._fit_columns(X)\n",
    "        \n",
    "        super(DPPRegressor, self).fit(X, y, coef_init=coef_init, intercept_init=intercept_init,\n",
    "            sample_weight=sample_weight)\n",
    "        self._reg_penalty(X)\n",
    "        return self\n",
    "    \n",
    "    def partial_fit(self, X, y, sample_weight=None):\n",
    "        X_ = X.copy()\n",
    "        self.seen_cols = list(set(self.seen_cols + X.columns.tolist()))\n",
    "        X = X[X.columns.difference(self.coef_info['excluded_cols'])]\n",
    "        \n",
    "        # TODO: add DPP selection\n",
    "        self._dpp_sel(X, y)\n",
    "        X = self._fit_columns(X_)\n",
    "        \n",
    "        # now update coefficients\n",
    "        n_samples, n_features = X.shape\n",
    "        coef_list = np.zeros(n_features, dtype=np.float64, order=\"C\")\n",
    "        coef_list[:len(self.coef_info['coef'])] = self.coef_info['coef']\n",
    "        self.coef_ = coef_list.copy()\n",
    "        \n",
    "        super(DPPRegressor, self).partial_fit(X, y, sample_weight=None)  \n",
    "        self._reg_penalty(X)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self._fit_columns(X, transform_only=True)\n",
    "        return super(DPPRegressor, self).predict(X)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPPRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, intergroup_thres=0.1, intragroup_alpha=0.05,\n",
       "       l1_ratio=0.15, learning_rate='invscaling', loss='squared_loss',\n",
       "       max_iter=1000, n_iter=None, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DPPRegressor(max_iter=1000)\n",
    "model.fit(X1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chapm\\anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2397: UserWarning: Warning: sample size too small for normal approximation.\n",
      "  warnings.warn(\"Warning: sample size too small for normal approximation.\")\n",
      "c:\\users\\chapm\\anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2422: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  z = (T - mn - correction) / se\n",
      "c:\\users\\chapm\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "c:\\users\\chapm\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "c:\\users\\chapm\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DPPRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, intergroup_thres=0.1, intragroup_alpha=0.05,\n",
       "       l1_ratio=0.15, learning_rate='invscaling', loss='squared_loss',\n",
       "       max_iter=1000, n_iter=None, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.partial_fit(pdf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-116.19851995,   25.32403802,  -20.08586253,  151.72629568,\n",
       "       -300.1945719 , -190.91521145,  -14.77283484, -124.69532061,\n",
       "        -94.7650173 , -202.36233902, -174.72808171, -122.48596748,\n",
       "        -47.80872778,   -6.22982992, -163.56915119,  241.12843811,\n",
       "        -38.05423521,  -86.9304594 ,   38.58058847, -299.16186659,\n",
       "        -84.46375207,   64.61166051, -272.95093609,    2.72379089,\n",
       "        -91.55662298, -297.16781277, -266.79257011,    1.2750348 ,\n",
       "         -6.98603111, -128.33825284, -145.57048332,  -40.23112192,\n",
       "        -39.49728685, -264.43551357,  -65.3518305 , -233.95642767,\n",
       "          5.81271655,  -32.41666936,   18.89888808, -309.71246434,\n",
       "        148.56684161,  101.63394671,  -36.28773047, -279.52492476,\n",
       "       -490.49845069,  245.25654126, -358.25756034,   35.85656779,\n",
       "         12.0346471 , -346.81883246,  -17.46827797,  169.56370463,\n",
       "       -207.56377903,  -85.75244977, -165.16899334,  -42.20948736,\n",
       "         69.05069415,  128.80275777,   -6.89233248,  -16.44131561,\n",
       "       -244.92122467,   -3.18114127, -249.39246175, -213.57752434,\n",
       "         98.52818349,  300.85078148,  -63.47818164,  -10.94713814,\n",
       "         65.48497478,  113.88417641,   90.24207688,   81.87117956,\n",
       "       -183.57558492,  -54.94681389,    5.79670067, -138.90122713,\n",
       "       -121.89298813,    3.20802556,  165.83850232,  151.53096627,\n",
       "         81.39907828,  -38.43916954,   90.32353178,   63.77318578,\n",
       "       -162.78981055,  -86.87635367,  102.53087371,  120.81721388,\n",
       "        138.81870163, -280.37046865, -266.39783554,   52.58688386,\n",
       "       -240.99926664, -177.5116706 , -228.22860655,   69.73374359,\n",
       "       -159.82775418, -462.27551068, -206.0772423 ,   88.48925246])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pdf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
