{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the _Online Group Feature Selection_ (OGFS) algorithm.\n",
    "\n",
    "OGFS uses Lasso, so we will default to Lasso in its filtering with a low tolerance.\n",
    "\n",
    "**Note**: The output of the algorithm is not to provide a model, but rather the present the group of selected (subset) of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression, make_classification\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import SPEC\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.mixture import BayesianGaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity_within_class(X, y):\n",
    "    return SPEC.similarity_classification(X, y)\n",
    "\n",
    "def similarity_between_class(X, y):\n",
    "    \"\"\"\n",
    "    Calculates betweenclass affinity X (data) y (labels)\n",
    "    \n",
    "    note that it only considers the labels\n",
    "    \"\"\"\n",
    "    y_series = pd.Series(y)\n",
    "    y_val = y_series.value_counts(normalize=True)\n",
    "    n_inv = 1.0/len(set(y))\n",
    "    \n",
    "    y_size = len(y)\n",
    "    sim_matrix = np.zeros((len(y), len(y)))\n",
    "    for s_i in range(y_size):\n",
    "        for s_j in range(y_size):\n",
    "            sim_matrix[s_i, s_j] = n_inv - y_val[y[s_i]] if y[s_i] == y[s_j] else n_inv\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_deciles(y, n=10, gmm=False):\n",
    "    \"\"\"\n",
    "    By default converts to deciles, can be changed based on choice of n.\n",
    "    \"\"\"\n",
    "    if gmm:\n",
    "        # this is experimental\n",
    "        bgm = BayesianGaussianMixture(n_components=10)\n",
    "        bgm.fit(y.reshape(-1, 1))\n",
    "        return bgm.predict(y.reshape(-1, 1))\n",
    "    return np.array(pd.cut(y, n, labels=range(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_features=100)\n",
    "pdf = pd.DataFrame(X)\n",
    "pdf.columns = ['c{}'.format(x) for x in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = pdf[['c{}'.format(x) for x in range(50, 100)]]\n",
    "X2 = pdf[['c{}'.format(x) for x in range(50)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spec_supervised(X, y, is_classification=True):\n",
    "    if not is_classification:\n",
    "        y = convert_to_deciles(y, 10, gmm=False)\n",
    "    W_w = similarity_within_class(X, y)\n",
    "    W_b = similarity_between_class(X, y)\n",
    "    s_w = SPEC.spec(**{'X': X, 'y': y, 'style':0, 'mode': 'raw', 'W': W_w})\n",
    "    s_b = SPEC.spec(**{'X': X, 'y': y, 'style':0, 'mode': 'raw', 'W': W_b})\n",
    "    return s_b, s_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_feats1(s_b, s_w, highest_best=True):\n",
    "    curr_u1 = []\n",
    "    curr_u2 = []\n",
    "    my_feats = []\n",
    "    prev_score = None\n",
    "    X = s_b/s_w\n",
    "    eval_order = np.argsort(X).flatten()\n",
    "    if highest_best:\n",
    "        eval_order = eval_order[::-1]\n",
    "    for idx in list(eval_order):\n",
    "        if prev_score is None:\n",
    "            curr_u1.append(s_b[idx])\n",
    "            curr_u2.append(s_w[idx])\n",
    "            my_feats.append(idx)\n",
    "        else:\n",
    "            test_u1 = curr_u1[:]\n",
    "            test_u2 = curr_u2[:]\n",
    "            test_u1.append(s_b[idx])\n",
    "            test_u2.append(s_w[idx])\n",
    "            score = ((np.sum(test_u1)/np.sum(test_u2)) - prev_score)\n",
    "            if score > 0.001:\n",
    "                my_feats.append(idx)\n",
    "                curr_u1.append(s_b[idx])\n",
    "                curr_u2.append(s_w[idx])\n",
    "        prev_score = np.sum(curr_u1)/np.sum(curr_u2)\n",
    "    return list(my_feats)\n",
    "\n",
    "def evaluate_feats2(X, alpha=0.05, highest_best=True):\n",
    "    \"\"\"\n",
    "    X is the raw scrores\n",
    "    alpha is the level of significance\n",
    "    \n",
    "    This version uses T-test\n",
    "    \n",
    "    Returns: set of indices indicating selected features.\n",
    "    \"\"\"\n",
    "    eval_order = np.argsort(X)\n",
    "    if highest_best:\n",
    "        eval_order = eval_order[::-1]\n",
    "    selected_feats = []\n",
    "    selected_idx = []\n",
    "    for idx in eval_order:\n",
    "        if len(selected_feats) == 0:\n",
    "            selected_feats.append(X[idx])\n",
    "            selected_idx.append(idx)\n",
    "            continue\n",
    "        # now continue on and decide what to do\n",
    "        mu = np.mean(selected_feats)\n",
    "        sigma = np.std(selected_feats)\n",
    "        U = len(selected_feats)\n",
    "        if sigma == 0.0 and U > 1:\n",
    "            return selected_idx\n",
    "        elif sigma == 0.0:\n",
    "            selected_feats.append(X[idx])\n",
    "            selected_idx.append(idx)\n",
    "            continue\n",
    "        \n",
    "        # otherwise compute score for T test.\n",
    "        t_stat = (mu - X[idx])/(sigma/np.sqrt(U))\n",
    "        t_alpha = stats.t.pdf(t_stat, U)\n",
    "        if t_alpha <= alpha:\n",
    "            selected_feats.append(X[idx])\n",
    "            selected_idx.append(idx)\n",
    "        else:\n",
    "            return selected_idx\n",
    "    return selected_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_feats(s_b, s_w, alpha=0.05):\n",
    "    set1 = evaluate_feats1(s_b,s_w)\n",
    "    set2 = evaluate_feats2(s_b/s_w, alpha)\n",
    "    return list(set(set1 + set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X2.copy()\n",
    "X_1 = np.array(X_)        \n",
    "s_b, s_w = spec_supervised(X_1, y, False)\n",
    "aa = evaluate_feats(s_b, s_w)\n",
    "col_sel = pdf.columns[aa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "class OGFSRegressor(SGDRegressor):\n",
    "    def __init__(self, loss=\"squared_loss\", penalty=\"l1\", alpha=0.0001,\n",
    "                 l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None,\n",
    "                 shuffle=True, verbose=0, epsilon=0.1,\n",
    "                 random_state=None, learning_rate=\"invscaling\", eta0=0.01,\n",
    "                 power_t=0.25, warm_start=False, average=False, n_iter=None, \n",
    "                 intragroup_alpha=0.05, intergroup_thres=None):\n",
    "        super(OGFSRegressor, self).__init__(loss=loss, penalty=penalty,\n",
    "                                           alpha=alpha, l1_ratio=l1_ratio,\n",
    "                                           fit_intercept=fit_intercept,\n",
    "                                           max_iter=max_iter, tol=tol,\n",
    "                                           shuffle=shuffle,\n",
    "                                           verbose=verbose,\n",
    "                                           epsilon=epsilon,\n",
    "                                           random_state=random_state,\n",
    "                                           learning_rate=learning_rate,\n",
    "                                           eta0=eta0, power_t=power_t,\n",
    "                                           warm_start=warm_start,\n",
    "                                           average=average, n_iter=n_iter)\n",
    "        \"\"\"\n",
    "        intragroup_alpha : the alpha level of t-test used to determine significance\n",
    "        intergroup_thres : the threshold for lasso to remove redundancy\n",
    "        \"\"\"\n",
    "        self.coef_info = {'cols': [], 'coef':[], 'excluded_cols': []}\n",
    "        self.seen_cols = []\n",
    "        self.base_shape = None\n",
    "        self.intragroup_alpha = intragroup_alpha\n",
    "        self.intergroup_thres = intergroup_thres if intergroup_thres is not None else epsilon\n",
    "    \n",
    "    def add_column_exclusion(self, cols):\n",
    "        self.coef_info['excluded_cols'] = self.coef_info['excluded_cols'] + cols\n",
    "        \n",
    "    def _fit_columns(self, X_, return_x=True, transform_only=False):\n",
    "        \"\"\"\n",
    "        Method filter through \"unselected\" columns. The goal of this \n",
    "        method is to filter any uninformative columns.\n",
    "        \n",
    "        This will be selected based on index only?\n",
    "        \n",
    "        If return_x is false, it will only return the boolean mask.\n",
    "        \"\"\"\n",
    "        X = X_[X_.columns.difference(self.coef_info['excluded_cols'])]\n",
    "        \n",
    "        # order the columns correctly...\n",
    "        col_order = self.coef_info['cols'] + list([x for x in X.columns if x not in self.coef_info['cols']])\n",
    "        X = X[col_order]\n",
    "        return X\n",
    "    \n",
    "    def _reg_penalty(self, X):\n",
    "        col_coef = [(col, coef) for col, coef in zip(X.columns.tolist(), self.coef_) if np.abs(coef) >= self.intergroup_thres]\n",
    "        self.coef_info['cols'] = [x for x, _ in col_coef]\n",
    "        self.coef_info['coef'] = [x for _, x in col_coef]\n",
    "        self.coef_info['excluded_cols'] = [x for x in self.seen_cols if x not in self.coef_info['cols']]\n",
    "        self.coef_ = np.array(self.coef_info['coef'])     \n",
    "            \n",
    "    def _spectral_sel(self, X_, y):\n",
    "        \"\"\"\n",
    "        Partial fit online group feature selection method to \n",
    "        perform spectral analysis on incoming feature set\n",
    "        to then expand the coefficient listing\n",
    "        \"\"\"\n",
    "        X = np.array(X_)        \n",
    "        s_b, s_w = spec_supervised(X, y, False)\n",
    "        col_sel = X_.columns[evaluate_feats(s_b, s_w)]\n",
    "        sel_cols = list(self.coef_info['cols']) + list(col_sel)\n",
    "        # update removed columns\n",
    "        self.coef_info['excluded_cols'] = [col for col in self.seen_cols if col not in sel_cols]\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, coef_init=None, intercept_init=None,\n",
    "            sample_weight=None):\n",
    "        X_ = X.copy()\n",
    "        self.seen_cols = list(set(self.seen_cols + X.columns.tolist()))\n",
    "        \n",
    "        # TODO: add the spectral selection here\n",
    "        self._spectral_sel(X, y)\n",
    "        X = self._fit_columns(X)\n",
    "        \n",
    "        super(OGFSRegressor, self).fit(X, y, coef_init=coef_init, intercept_init=intercept_init,\n",
    "            sample_weight=sample_weight)\n",
    "        self._reg_penalty(X)\n",
    "        return self\n",
    "    \n",
    "    def partial_fit(self, X, y, sample_weight=None):\n",
    "        X_ = X.copy()\n",
    "        self.seen_cols = list(set(self.seen_cols + X.columns.tolist()))\n",
    "        X = X[X.columns.difference(self.coef_info['excluded_cols'])]\n",
    "        \n",
    "        # TODO: add the spectral selection here\n",
    "        # it should only consider \"unseen\"\n",
    "        self._spectral_sel(X[X.columns.difference(self.coef_info['cols'])], y)\n",
    "        X = self._fit_columns(X)\n",
    "        \n",
    "        # now update coefficients\n",
    "        n_samples, n_features = X.shape\n",
    "        coef_list = np.zeros(n_features, dtype=np.float64, order=\"C\")\n",
    "        coef_list[:len(self.coef_info['coef'])] = self.coef_info['coef']\n",
    "        self.coef_ = coef_list.copy()\n",
    "        \n",
    "        super(OGFSRegressor, self).partial_fit(X, y, sample_weight=None)  \n",
    "        self._reg_penalty(X)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self._fit_columns(X, transform_only=True)\n",
    "        return super(OGFSRegressor, self).predict(X)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OGFSRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, intergroup_thres=0.1, intragroup_alpha=0.05,\n",
       "       l1_ratio=0.15, learning_rate='invscaling', loss='squared_loss',\n",
       "       max_iter=1000, n_iter=None, penalty='l1', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OGFSRegressor(max_iter=1000)\n",
    "model.fit(X1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OGFSRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, intergroup_thres=0.1, intragroup_alpha=0.05,\n",
       "       l1_ratio=0.15, learning_rate='invscaling', loss='squared_loss',\n",
       "       max_iter=1000, n_iter=None, penalty='l1', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.partial_fit(pdf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4.20399211,  -23.79420783,   72.65000239,  -22.29526175,\n",
       "        -70.44287091,   77.12159062,  164.70286036, -183.66103474,\n",
       "         33.15728032,  118.4157222 ,   23.62260588, -173.71254282,\n",
       "        -43.27094578,    8.01379961, -209.08455797,   48.87267741,\n",
       "        126.781505  ,  171.25639865, -207.89214382,    8.40472879,\n",
       "         61.9156414 ,   43.950742  , -122.89385665,   -0.94154365,\n",
       "        256.39464545,   85.81527225,   36.95240801,  -11.01273216,\n",
       "        -57.32230049,  -60.40259386,   37.64562428,   83.77717464,\n",
       "         96.42615472,  -61.6676576 ,  114.18348278,   41.77382645,\n",
       "          4.48693582,  -42.77718934, -154.2438299 ,   32.30700546,\n",
       "         54.70853432,  -88.39892099,  -22.90267357, -126.44500227,\n",
       "       -187.31247567,   55.43342648, -251.59664339,  -98.89955014,\n",
       "       -143.31289737,   13.48301526,   71.01640266,  112.94841177,\n",
       "         80.19293521,   63.41426843,  241.77801832, -155.92303532,\n",
       "         89.23871854, -181.68648948,   22.80913335,  -22.00219614,\n",
       "        -26.84660832,  -37.60546301,   83.26382754,  108.94775561,\n",
       "        -22.98192305,   56.99387644, -234.76574219,  -88.14442914,\n",
       "       -225.48702191,  169.76330865,  107.22044938,  178.42748173,\n",
       "        161.8334106 ,   38.84429757,    3.12073097,  -61.76341038,\n",
       "        -31.45842884,  -95.22495136,   54.88343712,   95.07071377,\n",
       "         73.45283526,  -36.98815433,  -96.92816064,   41.49791554,\n",
       "        -90.98575923,  168.84426647,  -98.19327848,  -55.8160627 ,\n",
       "         71.63863868,   -4.49313851,   45.61540172,  109.90642488,\n",
       "         20.03334279, -142.14240792, -188.77611288,   69.24620191,\n",
       "         -8.58291185,   71.61591896,  -72.5330467 , -167.38513667])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
