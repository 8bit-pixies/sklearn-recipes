{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from grafting_classifier import GraftingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from ogfs_classifier import OGFSClassifier\n",
    "from osfs_classifier import OSFSClassifier\n",
    "#from dpp_classifier import DPPClassifier\n",
    "#from dpp_classifier_dppsample import DPPClassifier as DPPClassifier0\n",
    "#from dpp_classifier_mitra import DPPClassifier as DPPClassifier2\n",
    "#from dpp_classifier_ogfs_dppsample import DPPClassifier as DPPClassifier3\n",
    "from dpp_classifier_supervised import DPPClassifier as DPPClassifier3\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "#import dask.dataframe as dd\n",
    "#import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uci\\\\Ionosphere_train.csv', 'uci\\\\spambase_train.csv', 'uci\\\\spectf_train.csv', 'uci\\\\wdbc_train.csv']\n"
     ]
    }
   ],
   "source": [
    "class_train = glob.glob(\"uci/*_train.csv\")\n",
    "print(class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_label(fname):\n",
    "    targetname = fname.replace(\".csv\", \".labels\")\n",
    "    return pd.read_csv(targetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_performance(mod, fpath, mod_name):\n",
    "    train1 = pd.read_csv(fpath).fillna(0)\n",
    "    y = np.array(train_label(fpath)).flatten()\n",
    "    \n",
    "    # simulate streaming...\n",
    "    # try splitting into groups of ~10,\n",
    "    # if there is no splits, try ~5.\n",
    "    train1_cols = np.array_split(range(train1.shape[1]), int(train1.shape[1]/10.0) + 1)\n",
    "    if len(train1_cols) == 1:\n",
    "        train1_cols = np.array_split(range(train1.shape[1]), int(train1.shape[1]/5.0) + 1)\n",
    "    all_cols = []\n",
    "\n",
    "    #mod = GraftingClassifier(max_iter=5)\n",
    "    if mod_name == 'Base':\n",
    "        mod.fit(train1, y)\n",
    "        results = {'accuracy': accuracy_score(y, mod.predict(train1)), \n",
    "               'logloss': log_loss(y, mod.predict_proba(train1)), \n",
    "               'feat_dim': mod.coef_.flatten().shape}\n",
    "        return results\n",
    "    \n",
    "    # lets normalise the dataset...\n",
    "    train1 = (train1 - train1.mean())/(np.maximum(train1.std(), 1))\n",
    "    for idx, collist in enumerate(train1_cols):\n",
    "        if idx == 0:\n",
    "            column_list = list(np.array(list(train1.columns))[collist])\n",
    "            mod.fit(train1[column_list], y)\n",
    "            all_cols.extend(list(collist))\n",
    "        else:\n",
    "            all_cols.extend(list(collist))\n",
    "            column_list = list(np.array(list(train1.columns))[all_cols])\n",
    "            mod.partial_fit(train1[column_list], y)\n",
    "        \n",
    "        # debugging\n",
    "        print_cond = True if idx % int((len(train1_cols)/10)+1) == 0 else False\n",
    "        if mod_name in ['Fast_OSFS', 'DPP', 'DPP3', 'OGFS'] and print_cond:\n",
    "            print(\"\\tmodel: {}, iter: {}\".format(mod_name, idx))\n",
    "        \n",
    "        # for fast osfs\n",
    "    if mod_name == 'Fast_OSFS':\n",
    "        mod._redundancy(train1, y, mode='all')\n",
    "    \n",
    "    results = {'accuracy': accuracy_score(y, mod.predict(train1)), \n",
    "               'logloss': log_loss(y, mod.predict_proba(train1)), \n",
    "               'feat_dim': mod.coef_.flatten().shape}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_models():\n",
    "    return [\n",
    "    #('Grafting', GraftingClassifier(max_iter=5, random_state=42)), \n",
    "    #('DPP', DPPClassifier(max_iter=5, random_state=42)), \n",
    "    #('DPP0', DPPClassifier0(max_iter=5, random_state=42)), \n",
    "    #('DPP2', DPPClassifier2(max_iter=5, random_state=42)),\n",
    "    ('DPP3', DPPClassifier3(max_iter=5, random_state=42)),\n",
    "    #('OGFS', OGFSClassifier(max_iter=5, random_state=42)),\n",
    "    #('OSFS', OSFSClassifier(max_iter=5, random_state=42, fast_osfs=False)),\n",
    "    #('Fast_OSFS', OSFSClassifier(max_iter=5, random_state=42)),\n",
    "    ('Base', SGDClassifier(loss='log', max_iter=5, random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uci\\Ionosphere_train.csv (351, 34)\n",
      "\tmodel: DPP3, iter: 0\n",
      "(351, 18)\n",
      "\tmodel: DPP3, iter: 1\n",
      "(351, 26)\n",
      "\tmodel: DPP3, iter: 2\n",
      "(351, 34)\n",
      "\tmodel: DPP3, iter: 3\n",
      "DPP3 {'accuracy': 0.87749287749287752, 'logloss': 1.0831890572014167, 'feat_dim': (34,)}\n",
      "Base {'accuracy': 0.91737891737891741, 'logloss': 1.9154349277794036, 'feat_dim': (34,)}\n"
     ]
    }
   ],
   "source": [
    "ex_dat = class_train[0]\n",
    "print(ex_dat, pd.read_csv(ex_dat).shape)\n",
    "models = create_models()\n",
    "for nm, mod in models:\n",
    "    print(nm, get_performance(mod, ex_dat, mod_name=nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uci\\spambase_train.csv (4601, 57)\n",
      "\tmodel: DPP3, iter: 0\n",
      "(4601, 20)\n",
      "\tmodel: DPP3, iter: 1\n",
      "(4601, 30)\n",
      "\tmodel: DPP3, iter: 2\n",
      "(4601, 28)\n",
      "\tmodel: DPP3, iter: 3\n",
      "(4601, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapm\\Anaconda3\\envs\\skrecipe\\lib\\site-packages\\scipy\\stats\\morestats.py:2397: UserWarning: Warning: sample size too small for normal approximation.\n",
      "  warnings.warn(\"Warning: sample size too small for normal approximation.\")\n",
      "C:\\Users\\chapm\\Anaconda3\\envs\\skrecipe\\lib\\site-packages\\scipy\\stats\\morestats.py:2422: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  z = (T - mn - correction) / se\n",
      "C:\\Users\\chapm\\Anaconda3\\envs\\skrecipe\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\chapm\\Anaconda3\\envs\\skrecipe\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\chapm\\Anaconda3\\envs\\skrecipe\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmodel: DPP3, iter: 4\n",
      "(4601, 45)\n",
      "\tmodel: DPP3, iter: 5\n",
      "DPP3 {'accuracy': 0.90871549663116713, 'logloss': 0.30587131671855494, 'feat_dim': (44,)}\n",
      "Base {'accuracy': 0.708324277331015, 'logloss': 10.070713136799997, 'feat_dim': (57,)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapm\\Anaconda3\\envs\\skrecipe\\lib\\site-packages\\sklearn\\linear_model\\base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "ex_dat = class_train[1]\n",
    "print(ex_dat, pd.read_csv(ex_dat).shape)\n",
    "models = create_models()\n",
    "for nm, mod in models:\n",
    "    print(nm, get_performance(mod, ex_dat, mod_name=nm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uci\\spectf_train.csv (267, 44)\n",
      "\tmodel: DPP3, iter: 0\n",
      "(267, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapm\\Documents\\GitHub\\sklearn-recipes\\streaming_take2\\SPEC.py:114: RuntimeWarning: invalid value encountered in power\n",
      "  d1 = np.power(np.array(W.sum(axis=1)), -0.5)\n",
      "C:\\Users\\chapm\\Documents\\GitHub\\sklearn-recipes\\streaming_take2\\SPEC.py:116: RuntimeWarning: invalid value encountered in power\n",
      "  d2 = np.power(np.array(W.sum(axis=1)), 0.5)\n",
      "C:\\Users\\chapm\\Anaconda3\\envs\\skrecipe\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:876: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return (self.a <= x) & (x <= self.b)\n",
      "C:\\Users\\chapm\\Anaconda3\\envs\\skrecipe\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:876: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return (self.a <= x) & (x <= self.b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmodel: DPP3, iter: 1\n",
      "(267, 27)\n",
      "\tmodel: DPP3, iter: 2\n",
      "(267, 28)\n",
      "\tmodel: DPP3, iter: 3\n",
      "(267, 26)\n",
      "\tmodel: DPP3, iter: 4\n",
      "DPP3 {'accuracy': 0.79400749063670417, 'logloss': 0.80127978578316683, 'feat_dim': (11,)}\n",
      "Base {'accuracy': 0.79400749063670417, 'logloss': 7.1147292199254215, 'feat_dim': (44,)}\n"
     ]
    }
   ],
   "source": [
    "ex_dat = class_train[2]\n",
    "print(ex_dat, pd.read_csv(ex_dat).shape)\n",
    "models = create_models()\n",
    "for nm, mod in models:\n",
    "    print(nm, get_performance(mod, ex_dat, mod_name=nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uci\\wdbc_train.csv (569, 30)\n",
      "\tmodel: DPP3, iter: 0\n",
      "(569, 16)\n",
      "\tmodel: DPP3, iter: 1\n",
      "(569, 22)\n",
      "\tmodel: DPP3, iter: 2\n",
      "(569, 23)\n",
      "\tmodel: DPP3, iter: 3\n",
      "DPP3 {'accuracy': 0.91036906854130051, 'logloss': 0.24975493601716769, 'feat_dim': (9,)}\n",
      "Base {'accuracy': 0.91564147627416526, 'logloss': 2.9136401879713767, 'feat_dim': (30,)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapm\\Anaconda3\\envs\\skrecipe\\lib\\site-packages\\sklearn\\linear_model\\base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "ex_dat = class_train[3]\n",
    "print(ex_dat, pd.read_csv(ex_dat).shape)\n",
    "models = create_models()\n",
    "for nm, mod in models:\n",
    "    print(nm, get_performance(mod, ex_dat, mod_name=nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:skrecipe]",
   "language": "python",
   "name": "conda-env-skrecipe-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
