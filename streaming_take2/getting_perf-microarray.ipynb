{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from grafting_classifier import GraftingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from ogfs_classifier import OGFSClassifier\n",
    "from dpp_classifier import DPPClassifier\n",
    "from dpp_classifier_mitra import DPPClassifier as DPPClassifier2\n",
    "from dpp_classifier_dppsample import DPPClassifier as DPPClassifier0\n",
    "from dpp_classifier_ogfs2 import DPPClassifier as DPPClassifier3\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "#import dask.dataframe as dd\n",
    "#import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['microarray\\\\colon_train.csv', 'microarray\\\\leukemia_train.csv', 'microarray\\\\lung_cancer_train.csv', 'microarray\\\\prostate_train.csv']\n"
     ]
    }
   ],
   "source": [
    "class_train = glob.glob(\"microarray/*_train.csv\")\n",
    "print(class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_label(fname):\n",
    "    targetname = fname.replace(\".csv\", \".labels\")\n",
    "    return pd.read_csv(targetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_performance(mod, fpath, base=False):\n",
    "    train1 = pd.read_csv(fpath).fillna(0)\n",
    "    y = np.array(train_label(fpath)).flatten()\n",
    "    \n",
    "    # simulate streaming...\n",
    "    # try splitting into groups of ~10,\n",
    "    # if there is no splits, try ~5.\n",
    "    train1_cols = np.array_split(range(train1.shape[1]), min(10, int(train1.shape[1]/10.0) + 1))\n",
    "    if len(train1_cols) == 1:\n",
    "        train1_cols = np.array_split(range(train1.shape[1]), min(10, int(train1.shape[1]/5.0) + 1))\n",
    "    all_cols = []\n",
    "\n",
    "    #mod = GraftingClassifier(max_iter=5)\n",
    "    if base:\n",
    "        mod.fit(train1, y)\n",
    "        results = {'accuracy': accuracy_score(y, mod.predict(train1)), \n",
    "               'logloss': log_loss(y, mod.predict_proba(train1)), \n",
    "               'feat_dim': mod.coef_.flatten().shape}\n",
    "        return results\n",
    "\n",
    "    for idx, collist in enumerate(train1_cols):\n",
    "        if idx == 0:\n",
    "            column_list = list(np.array(list(train1.columns))[collist])\n",
    "            mod.fit(train1[column_list], y)\n",
    "            all_cols.extend(list(collist))\n",
    "        else:\n",
    "            all_cols.extend(list(collist))\n",
    "            column_list = list(np.array(list(train1.columns))[all_cols])\n",
    "            mod.partial_fit(train1[column_list], y)\n",
    "    \n",
    "    results = {'accuracy': accuracy_score(y, mod.predict(train1)), \n",
    "               'logloss': log_loss(y, mod.predict_proba(train1)), \n",
    "               'feat_dim': mod.coef_.flatten().shape}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    #('Grafting', GraftingClassifier(max_iter=5, random_state=42)), \n",
    "    #('DPP', DPPClassifier(max_iter=5, random_state=42)), \n",
    "    ('DPP', DPPClassifier3(max_iter=5, random_state=42)), \n",
    "    #('DPP2', DPPClassifier2(max_iter=5, random_state=42)),\n",
    "    #('OGFS', OGFSClassifier(max_iter=5, random_state=42)),\n",
    "    ('Base', SGDClassifier(loss='log', max_iter=5, random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['microarray\\\\colon_train.csv', 'microarray\\\\leukemia_train.csv', 'microarray\\\\lung_cancer_train.csv', 'microarray\\\\prostate_train.csv']\n"
     ]
    }
   ],
   "source": [
    "class_train = glob.glob(\"microarray/*_train.csv\")\n",
    "print(class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ex_dat = class_train[0]\n",
    "#print(ex_dat)\n",
    "#for nm, mod in models:\n",
    "#    if nm != 'Base':\n",
    "#        print(nm, get_performance(mod, ex_dat))\n",
    "#    else:\n",
    "#        print(nm, get_performance(mod, ex_dat, base=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microarray\\leukemia_train.csv\n",
      "(72, 7129)\n",
      "(72, 1426)\n",
      "\tSampling DPP...\n",
      "\tSampling DPP Done!\n",
      "\tCalculating separability (covariance matrix)...\n",
      "\tCalculating separability Done!\n",
      "\tWilcoxon stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapm\\Anaconda3\\envs\\skrecipe\\lib\\site-packages\\scipy\\stats\\morestats.py:2397: UserWarning: Warning: sample size too small for normal approximation.\n",
      "  warnings.warn(\"Warning: sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWilcoxon stats Done!\n",
      "(72, 2139)\n",
      "\tSampling DPP...\n",
      "\tSampling DPP Done!\n",
      "\tCalculating separability (covariance matrix)...\n",
      "\tCalculating separability Done!\n",
      "\tWilcoxon stats...\n",
      "\tWilcoxon stats Done!\n",
      "(72, 2852)\n",
      "\tSampling DPP...\n",
      "\tSampling DPP Done!\n",
      "\tCalculating separability (covariance matrix)...\n",
      "\tCalculating separability Done!\n",
      "\tWilcoxon stats...\n",
      "\tWilcoxon stats Done!\n",
      "(72, 3565)\n",
      "\tSampling DPP...\n",
      "\tSampling DPP Done!\n",
      "\tCalculating separability (covariance matrix)...\n",
      "\tCalculating separability Done!\n",
      "\tWilcoxon stats...\n",
      "\tWilcoxon stats Done!\n",
      "(72, 4278)\n",
      "\tSampling DPP...\n",
      "\tSampling DPP Done!\n",
      "\tCalculating separability (covariance matrix)...\n",
      "\tCalculating separability Done!\n",
      "\tWilcoxon stats...\n",
      "\tWilcoxon stats Done!\n",
      "(72, 4991)\n",
      "\tSampling DPP...\n",
      "\tSampling DPP Done!\n",
      "\tCalculating separability (covariance matrix)...\n",
      "\tCalculating separability Done!\n",
      "\tWilcoxon stats...\n",
      "\tWilcoxon stats Done!\n",
      "(72, 5704)\n",
      "\tSampling DPP...\n",
      "\tSampling DPP Done!\n",
      "\tCalculating separability (covariance matrix)...\n",
      "\tCalculating separability Done!\n",
      "\tWilcoxon stats...\n",
      "\tWilcoxon stats Done!\n",
      "(72, 6417)\n",
      "\tSampling DPP...\n",
      "\tSampling DPP Done!\n",
      "\tCalculating separability (covariance matrix)...\n",
      "\tCalculating separability Done!\n",
      "\tWilcoxon stats...\n",
      "\tWilcoxon stats Done!\n",
      "(72, 7129)\n",
      "\tSampling DPP...\n",
      "\tSampling DPP Done!\n",
      "\tCalculating separability (covariance matrix)...\n",
      "\tCalculating separability Done!\n",
      "\tWilcoxon stats...\n",
      "\tWilcoxon stats Done!\n",
      "DPP {'accuracy': 0.34722222222222221, 'logloss': 22.546145702233364, 'feat_dim': (4069,)}\n",
      "Base {'accuracy': 1.0, 'logloss': 9.9920072216264148e-16, 'feat_dim': (7129,)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapm\\Anaconda3\\envs\\skrecipe\\lib\\site-packages\\sklearn\\linear_model\\base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "ex_dat = class_train[1]\n",
    "print(ex_dat)\n",
    "print(pd.read_csv(ex_dat).shape)\n",
    "for nm, mod in models:\n",
    "    if nm != 'Base':\n",
    "        print(nm, get_performance(mod, ex_dat))\n",
    "    else:\n",
    "        print(nm, get_performance(mod, ex_dat, base=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microarray\\lung_cancer_train.csv\n",
      "(181, 2508)\n",
      "\tSampling DPP...\n",
      "\tSampling DPP Done!\n",
      "\tCalculating separability (covariance matrix)...\n",
      "\tCalculating separability Done!\n",
      "\tWilcoxon stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapm\\Anaconda3\\envs\\skrecipe\\lib\\site-packages\\scipy\\stats\\morestats.py:2397: UserWarning: Warning: sample size too small for normal approximation.\n",
      "  warnings.warn(\"Warning: sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWilcoxon stats Done!\n",
      "(181, 3762)\n",
      "\tSampling DPP...\n",
      "\tSampling DPP Done!\n",
      "\tCalculating separability (covariance matrix)...\n",
      "\tCalculating separability Done!\n",
      "\tWilcoxon stats...\n",
      "\tWilcoxon stats Done!\n",
      "(181, 5015)\n",
      "\tSampling DPP...\n",
      "\tSampling DPP Done!\n",
      "\tCalculating separability (covariance matrix)...\n",
      "\tCalculating separability Done!\n",
      "\tWilcoxon stats...\n",
      "\tWilcoxon stats Done!\n",
      "(181, 6268)\n",
      "\tSampling DPP...\n",
      "\tSampling DPP Done!\n",
      "\tCalculating separability (covariance matrix)...\n"
     ]
    }
   ],
   "source": [
    "ex_dat = class_train[2]\n",
    "print(ex_dat)\n",
    "for nm, mod in models:\n",
    "    if nm != 'Base':\n",
    "        print(nm, get_performance(mod, ex_dat))\n",
    "    else:\n",
    "        print(nm, get_performance(mod, ex_dat, base=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_dat = class_train[3]\n",
    "print(ex_dat)\n",
    "for nm, mod in models:\n",
    "    if nm != 'Base':\n",
    "        print(nm, get_performance(mod, ex_dat))\n",
    "    else:\n",
    "        print(nm, get_performance(mod, ex_dat, base=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:skrecipe]",
   "language": "python",
   "name": "conda-env-skrecipe-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
