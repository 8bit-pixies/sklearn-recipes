{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from grafting_classifier import GraftingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from ogfs_classifier import OGFSClassifier\n",
    "from osfs_classifier import OSFSClassifier\n",
    "from dpp_classifier import DPPClassifier\n",
    "from dpp_classifier_mitra import DPPClassifier as DPPClassifier2\n",
    "from dpp_classifier_ogfs import DPPClassifier as DPPClassifier3\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "#import dask.dataframe as dd\n",
    "#import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['microarray\\\\colon_train.csv', 'microarray\\\\leukemia_train.csv', 'microarray\\\\lung_cancer_train.csv', 'microarray\\\\prostate_train.csv']\n"
     ]
    }
   ],
   "source": [
    "class_train = glob.glob(\"microarray/*_train.csv\")\n",
    "print(class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_label(fname):\n",
    "    targetname = fname.replace(\".csv\", \".labels\")\n",
    "    return pd.read_csv(targetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_performance(mod, fpath, base=False):\n",
    "    train1 = pd.read_csv(fpath).fillna(0)\n",
    "    y = np.array(train_label(fpath)).flatten()\n",
    "    \n",
    "    # simulate streaming...\n",
    "    # try splitting into groups of ~10,\n",
    "    # if there is no splits, try ~5.\n",
    "    train1_cols = np.array_split(range(train1.shape[1]), int(train1.shape[1]/10.0) + 1)\n",
    "    if len(train1_cols) == 1:\n",
    "        train1_cols = np.array_split(range(train1.shape[1]), int(train1.shape[1]/5.0) + 1)\n",
    "    all_cols = []\n",
    "\n",
    "    #mod = GraftingClassifier(max_iter=5)\n",
    "    if base:\n",
    "        mod.fit(train1, y)\n",
    "        results = {'accuracy': accuracy_score(y, mod.predict(train1)), \n",
    "               'logloss': log_loss(y, mod.predict_proba(train1)), \n",
    "               'feat_dim': mod.coef_.flatten().shape}\n",
    "        return results\n",
    "    \n",
    "    \n",
    "    for idx, collist in enumerate(train1_cols):\n",
    "        if idx == 0:\n",
    "            column_list = list(np.array(list(train1.columns))[collist])\n",
    "            mod.fit(train1[column_list], y)\n",
    "            all_cols.extend(list(collist))\n",
    "        else:\n",
    "            all_cols.extend(list(collist))\n",
    "            column_list = list(np.array(list(train1.columns))[all_cols])\n",
    "            mod.partial_fit(train1[column_list], y)\n",
    "    \n",
    "    results = {'accuracy': accuracy_score(y, mod.predict(train1)), \n",
    "               'logloss': log_loss(y, mod.predict_proba(train1)), \n",
    "               'feat_dim': mod.coef_.flatten().shape}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod = OSFSClassifier(max_iter=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpath = class_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1 = pd.read_csv(fpath).fillna(0)\n",
    "y = np.array(train_label(fpath)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1 = (train1 - train1.mean())/(np.maximum(train1.std(), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1_cols = np.array_split(range(train1.shape[1]), int(train1.shape[1]/10.0) + 1)\n",
    "if len(train1_cols) == 1:\n",
    "    train1_cols = np.array_split(range(train1.shape[1]), int(train1.shape[1]/5.0) + 1)\n",
    "all_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'accuracy': 0.58064516129032262, 'logloss': 3.5147263327881966, 'feat_dim': (3,)}\n",
      "10 {'accuracy': 0.83870967741935487, 'logloss': 3.2458229029093255, 'feat_dim': (35,)}\n",
      "20 {'accuracy': 0.69354838709677424, 'logloss': 8.3604802132901295, 'feat_dim': (52,)}\n",
      "30 {'accuracy': 0.79032258064516125, 'logloss': 5.3817704444111945, 'feat_dim': (75,)}\n",
      "40 {'accuracy': 0.85483870967741937, 'logloss': 3.3241350850662257, 'feat_dim': (108,)}\n",
      "50 {'accuracy': 0.67741935483870963, 'logloss': 8.9828191446205228, 'feat_dim': (134,)}\n",
      "60 {'accuracy': 0.72580645161290325, 'logloss': 8.4194215293829266, 'feat_dim': (159,)}\n",
      "70 {'accuracy': 0.91935483870967738, 'logloss': 2.26335557436804, 'feat_dim': (185,)}\n",
      "80 {'accuracy': 0.88709677419354838, 'logloss': 2.4297071780118875, 'feat_dim': (218,)}\n",
      "90 {'accuracy': 0.90322580645161288, 'logloss': 3.0038900890478537, 'feat_dim': (240,)}\n",
      "100 {'accuracy': 0.88709677419354838, 'logloss': 2.9995455091195455, 'feat_dim': (257,)}\n",
      "110 {'accuracy': 0.95161290322580649, 'logloss': 1.3928408007112993, 'feat_dim': (274,)}\n",
      "120 {'accuracy': 0.90322580645161288, 'logloss': 2.8492427458558387, 'feat_dim': (308,)}\n",
      "130 {'accuracy': 0.70967741935483875, 'logloss': 8.3306526431434911, 'feat_dim': (335,)}\n",
      "140 {'accuracy': 0.88709677419354838, 'logloss': 2.9968232009470093, 'feat_dim': (360,)}\n",
      "150 {'accuracy': 0.74193548387096775, 'logloss': 7.643811439973736, 'feat_dim': (381,)}\n",
      "160 {'accuracy': 0.85483870967741937, 'logloss': 4.8082803412510664, 'feat_dim': (406,)}\n",
      "170 {'accuracy': 0.77419354838709675, 'logloss': 7.0372039111129627, 'feat_dim': (427,)}\n",
      "180 {'accuracy': 0.75806451612903225, 'logloss': 7.7659312396251128, 'feat_dim': (449,)}\n",
      "190 {'accuracy': 0.61290322580645162, 'logloss': 11.924715965893524, 'feat_dim': (470,)}\n",
      "200 {'accuracy': 0.80645161290322576, 'logloss': 5.9516957386049656, 'feat_dim': (485,)}\n"
     ]
    }
   ],
   "source": [
    "for idx, collist in enumerate(train1_cols):\n",
    "    if idx == 0:\n",
    "        column_list = list(np.array(list(train1.columns))[collist])\n",
    "        mod.fit(train1[column_list], y)\n",
    "        all_cols.extend(list(collist))\n",
    "    else:\n",
    "        all_cols.extend(list(collist))\n",
    "        column_list = list(np.array(list(train1.columns))[all_cols])\n",
    "        mod.partial_fit(train1[column_list], y)\n",
    "    \n",
    "    if idx % 10 == 0:\n",
    "        results = {'accuracy': accuracy_score(y, mod.predict(train1[column_list])), \n",
    "               'logloss': log_loss(y, mod.predict_proba(train1[column_list])), \n",
    "               'feat_dim': mod.coef_.flatten().shape}\n",
    "        print(idx, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mod.coef_info['strong_dep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mod.coef_info['weak_dep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mod.coef_info['cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1515"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mod.coef_info['excluded_cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 485)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:skrecipe]",
   "language": "python",
   "name": "conda-env-skrecipe-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
