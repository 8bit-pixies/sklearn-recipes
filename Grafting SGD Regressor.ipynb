{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_regression()\n",
    "pdf = pd.DataFrame(X)\n",
    "pdf.columns = ['c{}'.format(x) for x in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = pdf[['c{}'.format(x) for x in range(50, 100)]]\n",
    "X2 = pdf[['c{}'.format(x) for x in range(50)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraftingRegressor(SGDRegressor):\n",
    "    def __init__(self, loss=\"squared_loss\", penalty=\"l2\", alpha=0.0001,\n",
    "                 l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None,\n",
    "                 shuffle=True, verbose=0, epsilon=0.1,\n",
    "                 random_state=None, learning_rate=\"invscaling\", eta0=0.01,\n",
    "                 power_t=0.25, warm_start=False, average=False, n_iter=None, reg_penalty=None):\n",
    "        super(GraftingRegressor, self).__init__(loss=loss, penalty=penalty,\n",
    "                                           alpha=alpha, l1_ratio=l1_ratio,\n",
    "                                           fit_intercept=fit_intercept,\n",
    "                                           max_iter=max_iter, tol=tol,\n",
    "                                           shuffle=shuffle,\n",
    "                                           verbose=verbose,\n",
    "                                           epsilon=epsilon,\n",
    "                                           random_state=random_state,\n",
    "                                           learning_rate=learning_rate,\n",
    "                                           eta0=eta0, power_t=power_t,\n",
    "                                           warm_start=warm_start,\n",
    "                                           average=average, n_iter=n_iter)\n",
    "        self.filter_cols = []\n",
    "        self.base_shape = None\n",
    "        self.reg_penalty = reg_penalty if reg_penalty is not None else l1_ratio\n",
    "    \n",
    "    def _fit_columns(self, X, return_x=True):\n",
    "        \"\"\"\n",
    "        Method filter through \"unselected\" columns. The goal of this \n",
    "        method is to filter any uninformative columns.\n",
    "        \n",
    "        This will be selected based on index only?\n",
    "        \n",
    "        If return_x is false, it will only return the boolean mask.\n",
    "        \"\"\"\n",
    "        import pandas\n",
    "        bool_mask = np.ones((X.shape[1],), dtype=np.bool)\n",
    "        if len(self.filter_cols) == 0:\n",
    "            if return_x:\n",
    "                return X\n",
    "            else:\n",
    "                return bool_mask\n",
    "        # otherwise...\n",
    "        bool_mask[self.filter_cols] = False\n",
    "        if not return_x:\n",
    "            return bool_mask\n",
    "        if type(X) is pandas.core.frame.DataFrame:\n",
    "            return X[X.columns[bool_mask]]\n",
    "        else:\n",
    "            return X[:, bool_mask]\n",
    "    \n",
    "    def _reg_penalty(self):\n",
    "        bool_mask = np.zeros((self.coef_.shape[0],), dtype=np.bool)\n",
    "        keep_cols = np.argwhere(np.abs(self.coef_) > self.reg_penalty)        \n",
    "        mask = np.array(list(set(keep_cols.flatten().tolist() + list(range(self.base_shape)))))\n",
    "        self.coef_ = self.coef_[mask]\n",
    "        bool_mask[mask] = True\n",
    "        self.filter_cols = np.argwhere(~bool_mask).flatten().tolist()        \n",
    "    \n",
    "    def _partial_grafting_fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Partial fit grafting method to expand the coefficient listing\n",
    "        to taking into account new coefficients\n",
    "        \"\"\"\n",
    "        # require to know the base shape to determine/\n",
    "        # check for irrelevant columns in the future.\n",
    "        self.base_shape = self.coef_.shape[0]\n",
    "        \n",
    "        X = self._fit_columns(X)\n",
    "        n_samples, n_features = X.shape\n",
    "        coef_list = np.zeros(n_features, dtype=np.float64, order=\"C\")\n",
    "        coef_list[:self.coef_.shape[0]] = self.coef_.copy()\n",
    "        self.coef_ = coef_list.copy()\n",
    "        \n",
    "    def partial_fit(self, X, y, sample_weight=None):\n",
    "        self._partial_grafting_fit(X, y)\n",
    "        super(GraftingRegressor, self).partial_fit(X, y, sample_weight=None)  \n",
    "        \n",
    "        # update parameters based on weight of regularizer penalty\n",
    "        self._reg_penalty()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self._fit_columns(X)\n",
    "        return super(GraftingRegressor, self).predict(X)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraftingRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "         fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "         loss='squared_loss', max_iter=1000, n_iter=None, penalty='l2',\n",
       "         power_t=0.25, random_state=None, reg_penalty=0.15, shuffle=True,\n",
       "         tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GraftingRegressor(max_iter=1000)\n",
    "model.fit(X1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraftingRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "         fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "         loss='squared_loss', max_iter=1000, n_iter=None, penalty='l2',\n",
       "         power_t=0.25, random_state=None, reg_penalty=0.15, shuffle=True,\n",
       "         tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.partial_fit(pdf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-114.43971872,   -2.74621982,    8.78567954,  -21.94898466,\n",
       "        -44.51252186,  -74.56822503, -117.05766613,  120.64896879,\n",
       "       -156.00418368,    8.37154169,   24.1505489 ,   -8.38998533,\n",
       "         37.53529908,  109.02879654, -257.51148353,  -22.6802784 ,\n",
       "        -86.06796807,  -40.64576564,  -32.40757129,  138.73804528,\n",
       "         94.49303679,   66.11147198,   62.18854392,   64.88996926,\n",
       "        146.8258968 ,   -5.88583302,   61.27349625,  -87.66576157,\n",
       "        166.9204851 ,  101.60153914,  168.66389505,   63.60562505,\n",
       "        -28.22730543,   42.47326142,  172.80092979,  -42.58925289,\n",
       "        124.11914053,  -50.43591372,   32.35131454,   29.01065903,\n",
       "        122.10597674,   30.81761033,  137.68123206,  -39.04492819,\n",
       "         70.13353093,   95.6700908 , -195.58640197,   81.70611645,\n",
       "        -28.66193324,   -8.64604973,   20.19410666,   41.92081642,\n",
       "         90.93855988,  143.6976966 ,  -13.58232536,  161.64478059,\n",
       "         31.50291865,   19.10969744,  -91.75938233,  116.45499654,\n",
       "        -18.55521293,  148.71062624, -135.34966895,  -49.88673848,\n",
       "         50.79749717, -200.75559866,  -32.0491365 ,  -94.08585772,\n",
       "        -59.46988416,  214.79177261,  -69.9935067 ,   79.26646496,\n",
       "         73.20031718,  -39.26293938,   -6.9705811 ,   98.24079339,\n",
       "        234.58941687, -118.47552907,  -33.92696657,  222.45657495,\n",
       "          8.21559294,  212.19543574,   52.77633742,   -9.33518071,\n",
       "        -45.44362049,  201.04824388,  127.19419587,  -21.1315596 ,\n",
       "         63.79095737,  -20.11185574,  -32.67390485,  -58.88030808,\n",
       "        117.22015817,   22.90944753,   12.82997864,  -11.22929995,\n",
       "         11.60743603,  132.60160125, -101.80311708,   17.59951412])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implement DPP version that is similar to what is done above\n",
    "\"\"\"\n",
    "\n",
    "class DPPRegressor(SGDRegressor):\n",
    "    def __init__(self, loss=\"squared_loss\", penalty=\"l2\", alpha=0.0001,\n",
    "                 l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None,\n",
    "                 shuffle=True, verbose=0, epsilon=0.1,\n",
    "                 random_state=None, learning_rate=\"invscaling\", eta0=0.01,\n",
    "                 power_t=0.25, warm_start=False, average=False, n_iter=None, reg_penalty=None):\n",
    "        super(GraftingRegressor, self).__init__(loss=loss, penalty=penalty,\n",
    "                                           alpha=alpha, l1_ratio=l1_ratio,\n",
    "                                           fit_intercept=fit_intercept,\n",
    "                                           max_iter=max_iter, tol=tol,\n",
    "                                           shuffle=shuffle,\n",
    "                                           verbose=verbose,\n",
    "                                           epsilon=epsilon,\n",
    "                                           random_state=random_state,\n",
    "                                           learning_rate=learning_rate,\n",
    "                                           eta0=eta0, power_t=power_t,\n",
    "                                           warm_start=warm_start,\n",
    "                                           average=average, n_iter=n_iter)\n",
    "        self.filter_cols = []\n",
    "        self.base_shape = None\n",
    "        self.reg_penalty = reg_penalty if reg_penalty is not None else l1_ratio\n",
    "    \n",
    "    def _fit_columns(self, X, return_x=True):\n",
    "        \"\"\"\n",
    "        Method filter through \"unselected\" columns. The goal of this \n",
    "        method is to filter any uninformative columns.\n",
    "        \n",
    "        This will be selected based on index only?\n",
    "        \n",
    "        If return_x is false, it will only return the boolean mask.\n",
    "        \"\"\"\n",
    "        import pandas\n",
    "        bool_mask = np.ones((X.shape[1],), dtype=np.bool)\n",
    "        if len(self.filter_cols) == 0:\n",
    "            if return_x:\n",
    "                return X\n",
    "            else:\n",
    "                return bool_mask\n",
    "        # otherwise...\n",
    "        bool_mask[self.filter_cols] = False\n",
    "        if not return_x:\n",
    "            return bool_mask\n",
    "        if type(X) is pandas.core.frame.DataFrame:\n",
    "            return X[X.columns[bool_mask]]\n",
    "        else:\n",
    "            return X[:, bool_mask]\n",
    "    \n",
    "    def _reg_penalty(self):\n",
    "        bool_mask = np.zeros((self.coef_.shape[0],), dtype=np.bool)\n",
    "        keep_cols = np.argwhere(np.abs(self.coef_) > self.reg_penalty)        \n",
    "        mask = np.array(list(set(keep_cols.flatten().tolist() + list(range(self.base_shape)))))\n",
    "        self.coef_ = self.coef_[mask]\n",
    "        bool_mask[mask] = True\n",
    "        self.filter_cols = np.argwhere(~bool_mask).flatten().tolist()        \n",
    "    \n",
    "    def _partial_grafting_fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Partial fit grafting method to expand the coefficient listing\n",
    "        to taking into account new coefficients\n",
    "        \"\"\"\n",
    "        # require to know the base shape to determine/\n",
    "        # check for irrelevant columns in the future.\n",
    "        self.base_shape = self.coef_.shape[0]\n",
    "        \n",
    "        X = self._fit_columns(X)\n",
    "        n_samples, n_features = X.shape\n",
    "        coef_list = np.zeros(n_features, dtype=np.float64, order=\"C\")\n",
    "        coef_list[:self.coef_.shape[0]] = self.coef_.copy()\n",
    "        self.coef_ = coef_list.copy()\n",
    "        \n",
    "    def partial_fit(self, X, y, sample_weight=None):\n",
    "        self._partial_grafting_fit(X, y)\n",
    "        super(GraftingRegressor, self).partial_fit(X, y, sample_weight=None)  \n",
    "        \n",
    "        # update parameters based on weight of regularizer penalty\n",
    "        self._reg_penalty()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self._fit_columns(X)\n",
    "        return super(GraftingRegressor, self).predict(X)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
