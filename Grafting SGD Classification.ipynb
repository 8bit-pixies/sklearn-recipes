{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification()\n",
    "pdf = pd.DataFrame(X)\n",
    "pdf.columns = ['c{}'.format(x) for x in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = pdf[['c{}'.format(x) for x in range(10, 20)]]\n",
    "X2 = pdf[['c{}'.format(x) for x in range(10)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraftingClassifier(SGDClassifier):\n",
    "    \"\"\"\n",
    "    Currently only supports logistic regression.    \n",
    "    \"\"\"\n",
    "    def __init__(self, loss=\"log\", penalty='l2', alpha=0.0001, l1_ratio=0.15,\n",
    "                 fit_intercept=True, max_iter=None, tol=None, shuffle=True,\n",
    "                 verbose=0, epsilon=0.1, n_jobs=1,\n",
    "                 random_state=None, learning_rate=\"optimal\", eta0=0.0,\n",
    "                 power_t=0.5, class_weight=None, warm_start=False,\n",
    "                 average=False, n_iter=None, reg_penalty=None):\n",
    "        super(GraftingClassifier, self).__init__(\n",
    "            loss=loss, penalty=penalty, alpha=alpha, l1_ratio=l1_ratio,\n",
    "            fit_intercept=fit_intercept, max_iter=max_iter, tol=tol,\n",
    "            shuffle=shuffle, verbose=verbose, epsilon=epsilon, n_jobs=n_jobs,\n",
    "            random_state=random_state, learning_rate=learning_rate, eta0=eta0,\n",
    "            power_t=power_t, class_weight=class_weight, warm_start=warm_start,\n",
    "            average=average, n_iter=n_iter)\n",
    "        self.filter_cols = []\n",
    "        self.base_shape = None\n",
    "        self.reg_penalty = reg_penalty if reg_penalty is not None else l1_ratio\n",
    "    \n",
    "    def _fit_columns(self, X, return_x=True):\n",
    "        \"\"\"\n",
    "        Method filter through \"unselected\" columns. The goal of this \n",
    "        method is to filter any uninformative columns.\n",
    "        \n",
    "        This will be selected based on index only?\n",
    "        \n",
    "        If return_x is false, it will only return the boolean mask.\n",
    "        \"\"\"\n",
    "        import pandas\n",
    "        bool_mask = np.ones((X.shape[1],), dtype=np.bool)\n",
    "        if len(self.filter_cols) == 0:\n",
    "            if return_x:\n",
    "                return X\n",
    "            else:\n",
    "                return bool_mask\n",
    "        # otherwise...\n",
    "        bool_mask[self.filter_cols] = False\n",
    "        if not return_x:\n",
    "            return bool_mask\n",
    "        if type(X) is pandas.core.frame.DataFrame:\n",
    "            return X[X.columns[bool_mask]]\n",
    "        else:\n",
    "            return X[:, bool_mask]\n",
    "    \n",
    "    def _reg_penalty(self, tot_new_feats, base_size):\n",
    "        remove_cols = np.argwhere(np.abs(self.coef_.flatten()[-tot_new_feats:]) < self.reg_penalty)\n",
    "        add_cols = np.argwhere(np.abs(self.coef_.flatten()[-tot_new_feats:]) >= self.reg_penalty)\n",
    "        base_coef = self.coef_.flatten()[:-tot_new_feats].tolist()\n",
    "        # adding new coefs\n",
    "        base_coef = base_coef + self.coef_.flatten()[-tot_new_feats:][add_cols].flatten().tolist()\n",
    "        self.coef_ = np.array(base_coef).reshape(1, -1)\n",
    "        remove_cols_offset = [base_size + x for x in remove_cols]\n",
    "        self.filter_cols.append(remove_cols_offset)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def _partial_grafting_fit(self, X_, y):\n",
    "        \"\"\"\n",
    "        Partial fit grafting method to expand the coefficient listing\n",
    "        to taking into account new coefficients\n",
    "        \"\"\"\n",
    "        # require to know the base shape to determine/\n",
    "        # check for irrelevant columns in the future.\n",
    "        self.base_shape = self.coef_.shape[0]\n",
    "        \n",
    "        X = self._fit_columns(X_)\n",
    "        n_samples, n_features = X.shape\n",
    "        coef_list = np.zeros(n_features, dtype=np.float64, order=\"C\")\n",
    "        coef_list[:self.coef_.flatten().shape[0]] = self.coef_.flatten()\n",
    "        self.coef_ = coef_list.reshape(1,-1)\n",
    "        \n",
    "    def partial_fit(self, X, y, sample_weight=None):\n",
    "        base_size = len(self.filter_cols) + self.coef_.flatten().shape[0]\n",
    "        tot_new_feats = X.shape[1] - base_size\n",
    "        self._partial_grafting_fit(X, y)\n",
    "        super(GraftingClassifier, self).partial_fit(X, y, sample_weight=None)  \n",
    "        \n",
    "        # update parameters based on weight of regularizer penalty\n",
    "        self._reg_penalty(tot_new_feats, base_size)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self._fit_columns(X)\n",
    "        return super(GraftingClassifier, self).predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = self._fit_columns(X)\n",
    "        return super(GraftingClassifier, self).predict_proba(X)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraftingClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "          epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "          learning_rate='optimal', loss='log', max_iter=1000, n_iter=None,\n",
       "          n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "          reg_penalty=0.15, shuffle=True, tol=None, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GraftingClassifier(max_iter=1000)\n",
    "model.fit(X1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraftingClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "          epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "          learning_rate='optimal', loss='log', max_iter=1000, n_iter=None,\n",
       "          n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "          reg_penalty=0.15, shuffle=True, tol=None, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.partial_fit(pdf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00619828,  0.99380172],\n",
       "       [ 0.92969369,  0.07030631],\n",
       "       [ 0.68502224,  0.31497776],\n",
       "       [ 0.11524396,  0.88475604],\n",
       "       [ 0.03516324,  0.96483676],\n",
       "       [ 0.35131229,  0.64868771],\n",
       "       [ 0.72360682,  0.27639318],\n",
       "       [ 0.7947508 ,  0.2052492 ],\n",
       "       [ 0.18609653,  0.81390347],\n",
       "       [ 0.17042461,  0.82957539],\n",
       "       [ 0.94364955,  0.05635045],\n",
       "       [ 0.72174869,  0.27825131],\n",
       "       [ 0.98252103,  0.01747897],\n",
       "       [ 0.60455504,  0.39544496],\n",
       "       [ 0.77980623,  0.22019377],\n",
       "       [ 0.69483036,  0.30516964],\n",
       "       [ 0.5413798 ,  0.4586202 ],\n",
       "       [ 0.3501247 ,  0.6498753 ],\n",
       "       [ 0.36370671,  0.63629329],\n",
       "       [ 0.5962762 ,  0.4037238 ],\n",
       "       [ 0.419771  ,  0.580229  ],\n",
       "       [ 0.89638916,  0.10361084],\n",
       "       [ 0.75839285,  0.24160715],\n",
       "       [ 0.82523315,  0.17476685],\n",
       "       [ 0.44215415,  0.55784585],\n",
       "       [ 0.05100563,  0.94899437],\n",
       "       [ 0.20269502,  0.79730498],\n",
       "       [ 0.62765282,  0.37234718],\n",
       "       [ 0.72584456,  0.27415544],\n",
       "       [ 0.84605548,  0.15394452],\n",
       "       [ 0.75882693,  0.24117307],\n",
       "       [ 0.14363298,  0.85636702],\n",
       "       [ 0.15704122,  0.84295878],\n",
       "       [ 0.91739279,  0.08260721],\n",
       "       [ 0.94488603,  0.05511397],\n",
       "       [ 0.7719733 ,  0.2280267 ],\n",
       "       [ 0.96367466,  0.03632534],\n",
       "       [ 0.68333343,  0.31666657],\n",
       "       [ 0.93804905,  0.06195095],\n",
       "       [ 0.36384688,  0.63615312],\n",
       "       [ 0.7702775 ,  0.2297225 ],\n",
       "       [ 0.97813235,  0.02186765],\n",
       "       [ 0.62574577,  0.37425423],\n",
       "       [ 0.55332863,  0.44667137],\n",
       "       [ 0.91327073,  0.08672927],\n",
       "       [ 0.78662022,  0.21337978],\n",
       "       [ 0.3903689 ,  0.6096311 ],\n",
       "       [ 0.28463065,  0.71536935],\n",
       "       [ 0.06154552,  0.93845448],\n",
       "       [ 0.58562644,  0.41437356],\n",
       "       [ 0.4934146 ,  0.5065854 ],\n",
       "       [ 0.85122699,  0.14877301],\n",
       "       [ 0.74105576,  0.25894424],\n",
       "       [ 0.83707032,  0.16292968],\n",
       "       [ 0.69330963,  0.30669037],\n",
       "       [ 0.04736971,  0.95263029],\n",
       "       [ 0.07786129,  0.92213871],\n",
       "       [ 0.57960624,  0.42039376],\n",
       "       [ 0.84517802,  0.15482198],\n",
       "       [ 0.91530769,  0.08469231],\n",
       "       [ 0.23628402,  0.76371598],\n",
       "       [ 0.22313465,  0.77686535],\n",
       "       [ 0.11976533,  0.88023467],\n",
       "       [ 0.66270921,  0.33729079],\n",
       "       [ 0.94216506,  0.05783494],\n",
       "       [ 0.97302726,  0.02697274],\n",
       "       [ 0.96673777,  0.03326223],\n",
       "       [ 0.99727629,  0.00272371],\n",
       "       [ 0.62624011,  0.37375989],\n",
       "       [ 0.67197917,  0.32802083],\n",
       "       [ 0.37715775,  0.62284225],\n",
       "       [ 0.90704241,  0.09295759],\n",
       "       [ 0.13518674,  0.86481326],\n",
       "       [ 0.35017109,  0.64982891],\n",
       "       [ 0.80306754,  0.19693246],\n",
       "       [ 0.18100188,  0.81899812],\n",
       "       [ 0.29705418,  0.70294582],\n",
       "       [ 0.18055756,  0.81944244],\n",
       "       [ 0.21488882,  0.78511118],\n",
       "       [ 0.27758515,  0.72241485],\n",
       "       [ 0.15424098,  0.84575902],\n",
       "       [ 0.34117787,  0.65882213],\n",
       "       [ 0.47389542,  0.52610458],\n",
       "       [ 0.08184066,  0.91815934],\n",
       "       [ 0.24141037,  0.75858963],\n",
       "       [ 0.37854512,  0.62145488],\n",
       "       [ 0.04068648,  0.95931352],\n",
       "       [ 0.80504507,  0.19495493],\n",
       "       [ 0.97835053,  0.02164947],\n",
       "       [ 0.28286714,  0.71713286],\n",
       "       [ 0.86638237,  0.13361763],\n",
       "       [ 0.04401544,  0.95598456],\n",
       "       [ 0.78790736,  0.21209264],\n",
       "       [ 0.37256829,  0.62743171],\n",
       "       [ 0.01175228,  0.98824772],\n",
       "       [ 0.21025498,  0.78974502],\n",
       "       [ 0.60456134,  0.39543866],\n",
       "       [ 0.09650353,  0.90349647],\n",
       "       [ 0.74493591,  0.25506409],\n",
       "       [ 0.68760358,  0.31239642]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
