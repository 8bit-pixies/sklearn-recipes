{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**when sampling from k-dpp**\n",
    "\n",
    "We shall sample until one of the following is met:\n",
    "\n",
    "*  Number of samples is complete based on PCA on kernel (choice of k)\n",
    "*  Stopping criterion based on wilcoxon non-parametric test (early stopping). Using library: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html\n",
    "\n",
    "For speed we will demo the Nystroem kernel\n",
    "\n",
    "Based on the following notebook: https://github.com/chappers/Context-driven-constraints-for-gradient-boosted-models/blob/master/autoML/streaming/dpp-groupfs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression, make_classification\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from dpp import sample_dpp, decompose_kernel, sample_conditional_dpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75436608850453835"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(np.random.normal(size=(100,)), np.random.normal(size=(100,))).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_regression()\n",
    "pdf = pd.DataFrame(X)\n",
    "pdf.columns = ['c{}'.format(x) for x in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = pdf[['c{}'.format(x) for x in range(50, 100)]]\n",
    "X2 = pdf[['c{}'.format(x) for x in range(50)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 13]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx for idx, x in enumerate(pdf.columns) if x in ['c0', 'c13']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chapm\\anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2397: UserWarning: Warning: sample size too small for normal approximation.\n",
      "  warnings.warn(\"Warning: sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=5.0, pvalue=0.47950012218695348)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon([1,2,3,4,5], [3,4,5,6,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implement DPP version that is similar to what is done above\n",
    "\n",
    "\n",
    "sketch of solution\n",
    "------------------\n",
    "\n",
    "DPP requires a known number of parameters to check at each partial fit!\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class DPPRegressor(SGDRegressor):\n",
    "    def __init__(self, loss=\"squared_loss\", penalty=\"l2\", alpha=0.0001,\n",
    "                 l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None,\n",
    "                 shuffle=True, verbose=0, epsilon=0.1,\n",
    "                 random_state=None, learning_rate=\"invscaling\", eta0=0.01,\n",
    "                 power_t=0.25, warm_start=False, average=False, n_iter=None,\n",
    "                 intragroup_alpha=0.05, intergroup_thres=None):\n",
    "        super(DPPRegressor, self).__init__(loss=loss, penalty=penalty,\n",
    "                                           alpha=alpha, l1_ratio=l1_ratio,\n",
    "                                           fit_intercept=fit_intercept,\n",
    "                                           max_iter=max_iter, tol=tol,\n",
    "                                           shuffle=shuffle,\n",
    "                                           verbose=verbose,\n",
    "                                           epsilon=epsilon,\n",
    "                                           random_state=random_state,\n",
    "                                           learning_rate=learning_rate,\n",
    "                                           eta0=eta0, power_t=power_t,\n",
    "                                           warm_start=warm_start,\n",
    "                                           average=average, n_iter=n_iter)\n",
    "        self.coef_info = {'cols': [], 'coef':[], 'excluded_cols': []}\n",
    "        self.seen_cols = []\n",
    "        self.base_shape = None\n",
    "        self.intragroup_alpha = intragroup_alpha\n",
    "        self.intergroup_thres = intergroup_thres if intergroup_thres is not None else epsilon\n",
    "    \n",
    "    def _dpp_estimate_k(self, L):\n",
    "        \"\"\"\n",
    "        L is the input kernel\n",
    "        \"\"\"\n",
    "        pca = PCA(n_components=None)\n",
    "        pca.fit(L)\n",
    "        return np.min(np.argwhere(np.cumsum(pca.explained_variance_ratio_) > \n",
    "                                  (1-self.intragroup_alpha)))\n",
    "        \n",
    "    \n",
    "    def add_column_exclusion(self, cols):\n",
    "        self.coef_info['excluded_cols'] = list(self.coef_info['excluded_cols']) + list(cols)\n",
    "        \n",
    "    def _fit_columns(self, X_, return_x=True, transform_only=False):\n",
    "        \"\"\"\n",
    "        Method filter through \"unselected\" columns. The goal of this \n",
    "        method is to filter any uninformative columns.\n",
    "        \n",
    "        This will be selected based on index only?\n",
    "        \n",
    "        If return_x is false, it will only return the boolean mask.\n",
    "        \"\"\"\n",
    "        X = X_[X_.columns.difference(self.coef_info['excluded_cols'])]\n",
    "        \n",
    "        # order the columns correctly...\n",
    "        col_order = self.coef_info['cols'] + list([x for x in X.columns if x not in self.coef_info['cols']])\n",
    "        X = X[col_order]\n",
    "        return X\n",
    "\n",
    "    def _reg_penalty(self, X):\n",
    "        col_coef = [(col, coef) for col, coef in zip(X.columns.tolist(), self.coef_) if np.abs(coef) >= self.intergroup_thres]\n",
    "        self.coef_info['cols'] = [x for x, _ in col_coef]\n",
    "        self.coef_info['coef'] = [x for _, x in col_coef]\n",
    "        self.coef_info['excluded_cols'] = [x for x in self.seen_cols if x not in self.coef_info['cols']]\n",
    "        self.coef_ = np.array(self.coef_info['coef'])  \n",
    "    \n",
    "    def _dpp_sel(self, X_, y=None):\n",
    "        \"\"\"\n",
    "        DPP only relies on X. \n",
    "        \n",
    "        We will condition the sampling based on:\n",
    "        *  `self.coef_info['cols']`\n",
    "        \"\"\"\n",
    "        X = np.array(X_)\n",
    "        if X.shape[0] < 1000:\n",
    "            feat_dist = rbf_kernel(X.T)\n",
    "        else:\n",
    "            feat_dist = Nystroem().fit_transform(X.T)\n",
    "        k = self._dpp_estimate_k(feat_dist) - len(self.coef_info['cols'])\n",
    "                \n",
    "        if len(self.coef_info['cols']) == 0:\n",
    "            feat_index = sample_dpp(decompose_kernel(feat_dist), k=k)\n",
    "        else:\n",
    "            cols_to_index = [idx for idx, x in enumerate(X_.columns) if x in self.coef_info['cols']]\n",
    "            feat_index = sample_conditional_dpp(feat_dist, cols_to_index, k=k)\n",
    "        \n",
    "        # iterate over feat_index to determine \n",
    "        # information on wilcoxon test\n",
    "        feat_check = []\n",
    "        excl_check = []\n",
    "        for idx1, val1 in enumerate(feat_index):\n",
    "            for idx2, val2 in enumerate(feat_index):\n",
    "                if idx1 == 0:\n",
    "                    feat_check.append(val1)\n",
    "                if idx1 <= idx2 or idx1 in excl_check or idx2 in excl_check:\n",
    "                    continue\n",
    "                \n",
    "                if wilcoxon(X[:, val1], X[:, val2]).pvalue >= self.intragroup_alpha:\n",
    "                    feat_check.append(val1)\n",
    "                    feat_check.append(val2)\n",
    "                    feat_check = list(set(feat_check))\n",
    "                else:\n",
    "                    excl_check.append(val2)\n",
    "        \n",
    "        index_to_col = [col for idx, col in enumerate(X_.columns) if idx in feat_check]\n",
    "        self.coef_info['cols'] = list(set(self.coef_info['cols'] + index_to_col))\n",
    "        col_rem = X_.columns.difference(self.coef_info['cols'])\n",
    "        self.add_column_exclusion(col_rem)        \n",
    "        \n",
    "    def fit(self, X, y, coef_init=None, intercept_init=None,\n",
    "            sample_weight=None):\n",
    "        self.seen_cols = list(set(self.seen_cols + X.columns.tolist()))\n",
    "        \n",
    "        # TODO: add DPP selection\n",
    "        self.coef_info = {'cols': [], 'coef':[], 'excluded_cols': []}\n",
    "        self._dpp_sel(X, y)\n",
    "        X = self._fit_columns(X)\n",
    "        \n",
    "        super(DPPRegressor, self).fit(X, y, coef_init=coef_init, intercept_init=intercept_init,\n",
    "            sample_weight=sample_weight)\n",
    "        self._reg_penalty(X)\n",
    "        return self\n",
    "    \n",
    "    def partial_fit(self, X, y, sample_weight=None):\n",
    "        X_ = X.copy()\n",
    "        self.seen_cols = list(set(self.seen_cols + X.columns.tolist()))\n",
    "        X = X[X.columns.difference(self.coef_info['excluded_cols'])]\n",
    "        \n",
    "        # TODO: add DPP selection\n",
    "        self._dpp_sel(X, y)\n",
    "        X = self._fit_columns(X_)\n",
    "        \n",
    "        # now update coefficients\n",
    "        n_samples, n_features = X.shape\n",
    "        coef_list = np.zeros(n_features, dtype=np.float64, order=\"C\")\n",
    "        coef_list[:len(self.coef_info['coef'])] = self.coef_info['coef']\n",
    "        self.coef_ = coef_list.copy()\n",
    "        \n",
    "        super(DPPRegressor, self).partial_fit(X, y, sample_weight=None)  \n",
    "        self._reg_penalty(X)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self._fit_columns(X, transform_only=True)\n",
    "        return super(DPPRegressor, self).predict(X)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPPRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, intergroup_thres=0.1, intragroup_alpha=0.05,\n",
       "       l1_ratio=0.15, learning_rate='invscaling', loss='squared_loss',\n",
       "       max_iter=1000, n_iter=None, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DPPRegressor(max_iter=1000)\n",
    "model.fit(X1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chapm\\anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2397: UserWarning: Warning: sample size too small for normal approximation.\n",
      "  warnings.warn(\"Warning: sample size too small for normal approximation.\")\n",
      "c:\\users\\chapm\\anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2422: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  z = (T - mn - correction) / se\n",
      "c:\\users\\chapm\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "c:\\users\\chapm\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "c:\\users\\chapm\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DPPRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, intergroup_thres=0.1, intragroup_alpha=0.05,\n",
       "       l1_ratio=0.15, learning_rate='invscaling', loss='squared_loss',\n",
       "       max_iter=1000, n_iter=None, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.partial_fit(pdf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -81.00484185,  -80.24149587, -150.32328797, -292.06553898,\n",
       "        175.72379246, -167.2613617 ,  175.33699845, -110.09017795,\n",
       "         -0.72561681,  116.69090839,  -16.41150816,  133.33847063,\n",
       "        -39.06257894,  122.51105999,  153.99293612,  217.95304832,\n",
       "       -117.76858084,   82.53105574, -245.35290203, -296.46781347,\n",
       "        -60.67233921,  118.91951241,   64.7416485 ,   45.17460295,\n",
       "       -328.948595  , -294.64438618,  -26.59657255, -248.88541449,\n",
       "         21.99784509,  -29.16235481,   -0.66495049,   44.24337654,\n",
       "       -226.42840901,  348.74132991,  -73.12690453,   90.44083714,\n",
       "        167.07641384,  147.90971198,  -84.17610109,  247.47423489,\n",
       "        -52.07154569,   -4.03952675,   88.87122292,  -80.79605365,\n",
       "        396.27449861, -270.09732071, -134.43344724,   98.57747114,\n",
       "        103.30120562,   35.3892107 ,  368.01475183,   75.03497192,\n",
       "       -397.08019124,  319.41565209,  330.68867796, -136.58272347,\n",
       "       -402.06225048,   25.41300031,  130.09247929,  -18.37057711,\n",
       "       -182.63831993,  143.10316033,  112.23500477,   18.76024341,\n",
       "        367.5034752 , -259.18065216,  -33.17340008,  338.0587247 ,\n",
       "       -188.24688713, -199.99738509,   66.8179205 ,   56.97134083,\n",
       "       -314.77680201, -125.48046395,  235.79688631,  -14.50888959,\n",
       "       -177.37062647,   33.03286129, -202.89433806,  -90.89690649,\n",
       "        118.80795301,  165.06995136,  156.80014717,   10.55923693,\n",
       "       -257.95209637,   86.97070429,   -5.96003165,  174.07554047,\n",
       "         22.40403508,  115.74882876, -314.80224889, -124.20665337,\n",
       "        -34.94684618,  114.10386907,   89.84619284, -164.189285  ,\n",
       "        625.9093156 ,    3.19632604,  450.22324332,  104.79828575])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
