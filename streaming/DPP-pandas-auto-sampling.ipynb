{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**when sampling from k-dpp**\n",
    "\n",
    "We shall sample until one of the following is met:\n",
    "\n",
    "*  Number of samples is complete based on PCA on kernel (choice of k)\n",
    "*  Stopping criterion based on wilcoxon non-parametric test (early stopping). Using library: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html\n",
    "\n",
    "For speed we will demo the Nystroem kernel\n",
    "\n",
    "Based on the following notebook: https://github.com/chappers/Context-driven-constraints-for-gradient-boosted-models/blob/master/autoML/streaming/dpp-groupfs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression, make_classification\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from dpp import sample_dpp, decompose_kernel, sample_conditional_dpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88517700227168383"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(np.random.normal(size=(100,)), np.random.normal(size=(100,))).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_regression()\n",
    "pdf = pd.DataFrame(X)\n",
    "pdf.columns = ['c{}'.format(x) for x in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = pdf[['c{}'.format(x) for x in range(50, 100)]]\n",
    "X2 = pdf[['c{}'.format(x) for x in range(50)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 13]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx for idx, x in enumerate(pdf.columns) if x in ['c0', 'c13']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wilcoxon_group(X, f):\n",
    "    # X is a matrix, f is a single vector\n",
    "    if len(X.shape) == 1:\n",
    "        return wilcoxon(X, f).pvalue\n",
    "    # now we shall perform and check each one...and return only the lowest pvalue\n",
    "    return np.min([wilcoxon(x, f) for x in X.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implement DPP version that is similar to what is done above\n",
    "\n",
    "\n",
    "sketch of solution\n",
    "------------------\n",
    "\n",
    "DPP requires a known number of parameters to check at each partial fit!\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class DPPRegressor(SGDRegressor):\n",
    "    def __init__(self, loss=\"squared_loss\", penalty=\"l2\", alpha=0.0001,\n",
    "                 l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None,\n",
    "                 shuffle=True, verbose=0, epsilon=0.1,\n",
    "                 random_state=None, learning_rate=\"invscaling\", eta0=0.01,\n",
    "                 power_t=0.25, warm_start=False, average=False, n_iter=None,\n",
    "                 intragroup_alpha=0.05, intergroup_thres=None):\n",
    "        super(DPPRegressor, self).__init__(loss=loss, penalty=penalty,\n",
    "                                           alpha=alpha, l1_ratio=l1_ratio,\n",
    "                                           fit_intercept=fit_intercept,\n",
    "                                           max_iter=max_iter, tol=tol,\n",
    "                                           shuffle=shuffle,\n",
    "                                           verbose=verbose,\n",
    "                                           epsilon=epsilon,\n",
    "                                           random_state=random_state,\n",
    "                                           learning_rate=learning_rate,\n",
    "                                           eta0=eta0, power_t=power_t,\n",
    "                                           warm_start=warm_start,\n",
    "                                           average=average, n_iter=n_iter)\n",
    "        self.coef_info = {'cols': [], 'coef':[], 'excluded_cols': []}\n",
    "        self.seen_cols = []\n",
    "        self.base_shape = None\n",
    "        self.intragroup_alpha = intragroup_alpha\n",
    "        self.intergroup_thres = intergroup_thres if intergroup_thres is not None else epsilon\n",
    "    \n",
    "    def _dpp_estimate_k(self, L):\n",
    "        \"\"\"\n",
    "        L is the input kernel\n",
    "        \"\"\"\n",
    "        pca = PCA(n_components=None)\n",
    "        pca.fit(L)\n",
    "        return np.min(np.argwhere(np.cumsum(pca.explained_variance_ratio_) > \n",
    "                                  (1-self.intragroup_alpha)))\n",
    "        \n",
    "    \n",
    "    def add_column_exclusion(self, cols):\n",
    "        self.coef_info['excluded_cols'] = list(self.coef_info['excluded_cols']) + list(cols)\n",
    "        \n",
    "    def _fit_columns(self, X_, return_x=True, transform_only=False):\n",
    "        \"\"\"\n",
    "        Method filter through \"unselected\" columns. The goal of this \n",
    "        method is to filter any uninformative columns.\n",
    "        \n",
    "        This will be selected based on index only?\n",
    "        \n",
    "        If return_x is false, it will only return the boolean mask.\n",
    "        \"\"\"\n",
    "        X = X_[X_.columns.difference(self.coef_info['excluded_cols'])]\n",
    "        \n",
    "        # order the columns correctly...\n",
    "        col_order = self.coef_info['cols'] + list([x for x in X.columns if x not in self.coef_info['cols']])\n",
    "        X = X[col_order]\n",
    "        return X\n",
    "\n",
    "    def _reg_penalty(self, X):\n",
    "        col_coef = [(col, coef) for col, coef in zip(X.columns.tolist(), self.coef_) if np.abs(coef) >= self.intergroup_thres]\n",
    "        self.coef_info['cols'] = [x for x, _ in col_coef]\n",
    "        self.coef_info['coef'] = [x for _, x in col_coef]\n",
    "        self.coef_info['excluded_cols'] = [x for x in self.seen_cols if x not in self.coef_info['cols']]\n",
    "        self.coef_ = np.array(self.coef_info['coef'])  \n",
    "    \n",
    "    def _dpp_sel(self, X_, y=None):\n",
    "        \"\"\"\n",
    "        DPP only relies on X. \n",
    "        \n",
    "        We will condition the sampling based on:\n",
    "        *  `self.coef_info['cols']`\n",
    "        \n",
    "        After sampling it will go ahead and then perform grouped wilcoxon selection.\n",
    "        \"\"\"\n",
    "        X = np.array(X_)\n",
    "        if X.shape[0] < 1000:\n",
    "            feat_dist = rbf_kernel(X.T)\n",
    "        else:\n",
    "            feat_dist = Nystroem().fit_transform(X.T)\n",
    "        k = self._dpp_estimate_k(feat_dist) - len(self.coef_info['cols'])\n",
    "                \n",
    "        if len(self.coef_info['cols']) == 0:\n",
    "            feat_index = sample_dpp(decompose_kernel(feat_dist), k=k)\n",
    "        else:\n",
    "            cols_to_index = [idx for idx, x in enumerate(X_.columns) if x in self.coef_info['cols']]\n",
    "            feat_index = sample_conditional_dpp(feat_dist, cols_to_index, k=k)\n",
    "        \n",
    "        # iterate over feat_index to determine \n",
    "        # information on wilcoxon test\n",
    "        # as the feat index are already \"ordered\" as that is how DPP would\n",
    "        # perform the sampling - we will do the single pass in the same\n",
    "        # way it was approached in the OGFS\n",
    "        feat_check = []\n",
    "        excl_check = []\n",
    "        X_sel = X[:, feat_index]\n",
    "        \n",
    "        for idx, feat in enumerate(X_sel.T):\n",
    "            if len(feat_check) == 0:\n",
    "                feat_check.append(idx)\n",
    "                continue\n",
    "            if wilcoxon_group(X_sel[:, feat_check], feat) >= self.intragroup_alpha:\n",
    "                feat_check.append(idx)\n",
    "            else:\n",
    "                excl_check.append(idx)\n",
    "        index_to_col = [col for idx, col in enumerate(X_.columns) if idx in feat_check]\n",
    "        self.coef_info['cols'] = list(set(self.coef_info['cols'] + index_to_col))\n",
    "        col_rem = X_.columns.difference(self.coef_info['cols'])\n",
    "        self.add_column_exclusion(col_rem)        \n",
    "        \n",
    "    def fit(self, X, y, coef_init=None, intercept_init=None,\n",
    "            sample_weight=None):\n",
    "        self.seen_cols = list(set(self.seen_cols + X.columns.tolist()))\n",
    "        \n",
    "        # TODO: add DPP selection\n",
    "        self.coef_info = {'cols': [], 'coef':[], 'excluded_cols': []}\n",
    "        self._dpp_sel(X, y)\n",
    "        X = self._fit_columns(X)\n",
    "        \n",
    "        super(DPPRegressor, self).fit(X, y, coef_init=coef_init, intercept_init=intercept_init,\n",
    "            sample_weight=sample_weight)\n",
    "        self._reg_penalty(X)\n",
    "        return self\n",
    "    \n",
    "    def partial_fit(self, X, y, sample_weight=None):\n",
    "        X_ = X.copy()\n",
    "        self.seen_cols = list(set(self.seen_cols + X.columns.tolist()))\n",
    "        X = X[X.columns.difference(self.coef_info['excluded_cols'])]\n",
    "        \n",
    "        # TODO: add DPP selection\n",
    "        self._dpp_sel(X, y)\n",
    "        X = self._fit_columns(X_)\n",
    "        \n",
    "        # now update coefficients\n",
    "        n_samples, n_features = X.shape\n",
    "        coef_list = np.zeros(n_features, dtype=np.float64, order=\"C\")\n",
    "        coef_list[:len(self.coef_info['coef'])] = self.coef_info['coef']\n",
    "        self.coef_ = coef_list.copy()\n",
    "        \n",
    "        super(DPPRegressor, self).partial_fit(X, y, sample_weight=None)  \n",
    "        self._reg_penalty(X)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self._fit_columns(X, transform_only=True)\n",
    "        return super(DPPRegressor, self).predict(X)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPPRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, intergroup_thres=0.1, intragroup_alpha=0.05,\n",
       "       l1_ratio=0.15, learning_rate='invscaling', loss='squared_loss',\n",
       "       max_iter=1000, n_iter=None, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DPPRegressor(max_iter=1000)\n",
    "model.fit(X1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapm\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2397: UserWarning: Warning: sample size too small for normal approximation.\n",
      "  warnings.warn(\"Warning: sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DPPRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, intergroup_thres=0.1, intragroup_alpha=0.05,\n",
       "       l1_ratio=0.15, learning_rate='invscaling', loss='squared_loss',\n",
       "       max_iter=1000, n_iter=None, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.partial_fit(pdf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  31.11327576,  -26.45085912,   38.88040298,  -41.9506178 ,\n",
       "         89.39200329,   23.49516272, -115.04548581, -125.58254678,\n",
       "       -167.48808718,   17.12693695,  -38.44483027,  -41.86141787,\n",
       "        -18.6831682 ,  -41.81970281,  -55.61526654,   27.59532971,\n",
       "       -131.54265632,  -33.23935851,  307.27961312, -112.02837275,\n",
       "        110.93391743,  101.47661334, -161.23925395,   67.40773943,\n",
       "        100.77759422,   62.00728954,  -60.5618071 ,   73.29480139,\n",
       "         -7.45669909,   15.67877707,  -96.0702959 ,   31.18279288,\n",
       "         21.81182396,   26.75446196,  -51.53641831,  -63.92094516,\n",
       "        -68.63531281,   67.2121549 ,   90.13679657,  -20.48887632,\n",
       "        -90.40697997,   43.06208911,  -22.29830744,   39.40375014,\n",
       "         41.40048909,   -3.84975291,   66.63610523,  168.77875654,\n",
       "        189.10687949,  -67.74729503, -148.84714207,  132.94057874,\n",
       "        -63.4385876 ,   24.31454855,  -37.01478321,   62.20525127,\n",
       "         -5.0039112 ,   11.49671241,  -81.57514493,  -88.68656537,\n",
       "        -79.54966934, -133.2707007 ,   20.59862949,  -82.47592301,\n",
       "        -46.8950208 ,  -72.91932287,  169.98893701,  111.0013502 ,\n",
       "         12.26493675,   84.91946618,   96.12288769,   35.17256885,\n",
       "        125.73845726,  -40.36810942,  135.74023278,  -54.99906967,\n",
       "        119.92741737,   89.68708442,  -51.71184976,   41.59577324,\n",
       "       -152.09782627,   27.3012484 ,   72.80783195,   73.76980535,\n",
       "        -99.76011809,  -20.99587348,   64.4849747 ,   23.29582533,\n",
       "        -19.94068515,   38.67518618, -127.53532073,  101.22414628,\n",
       "        -12.58320453,   47.78408965,  109.91905471,   43.25863004,\n",
       "       -123.20684278,  -69.35725891,   53.33788818, -146.35109178])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
