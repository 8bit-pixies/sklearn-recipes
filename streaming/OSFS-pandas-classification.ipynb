{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of OSFS using conditional dependence information as shown in LOFS libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression, make_classification\n",
    "from sklearn.linear_model import SGDRegressor, SGDClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from osfs_util import dependence_test, fisher_test\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.mixture import BayesianGaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_features=100)\n",
    "pdf = pd.DataFrame(X)\n",
    "pdf.columns = ['c{}'.format(x) for x in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = pdf[['c{}'.format(x) for x in range(50, 100)]]\n",
    "X2 = pdf[['c{}'.format(x) for x in range(50)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.random.normal(size=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "class OSFSClassifier(SGDClassifier):\n",
    "    def __init__(self, loss=\"log\", penalty='l2', alpha=0.0001, l1_ratio=0.15,\n",
    "                 fit_intercept=True, max_iter=None, tol=None, shuffle=True,\n",
    "                 verbose=0, epsilon=0.1, n_jobs=1,\n",
    "                 random_state=None, learning_rate=\"optimal\", eta0=0.0,\n",
    "                 power_t=0.5, class_weight=None, warm_start=False,\n",
    "                 average=False, n_iter=None, \n",
    "                 relevance_alpha=0.05):\n",
    "        super(OSFSClassifier, self).__init__(\n",
    "            loss=loss, penalty=penalty, alpha=alpha, l1_ratio=l1_ratio,\n",
    "            fit_intercept=fit_intercept, max_iter=max_iter, tol=tol,\n",
    "            shuffle=shuffle, verbose=verbose, epsilon=epsilon, n_jobs=n_jobs,\n",
    "            random_state=random_state, learning_rate=learning_rate, eta0=eta0,\n",
    "            power_t=power_t, class_weight=class_weight, warm_start=warm_start,\n",
    "            average=average, n_iter=n_iter)\n",
    "        \"\"\"\n",
    "        relevance_alpha: the alpha level for the conditional independence statistics tests\n",
    "        \"\"\"\n",
    "        self.coef_info = {'cols': [], 'coef':[], 'excluded_cols': [], \n",
    "                          'strong_dep': [], 'weak_dep': []}\n",
    "        self.seen_cols = []\n",
    "        self.base_shape = None\n",
    "        self.relevance_alpha = relevance_alpha\n",
    "    \n",
    "    def add_column_exclusion(self, cols):\n",
    "        self.coef_info['excluded_cols'] = self.coef_info['excluded_cols'] + cols\n",
    "        \n",
    "    def _fit_columns(self, X_, return_x=True, transform_only=False):\n",
    "        \"\"\"\n",
    "        Method filter through \"unselected\" columns. The goal of this \n",
    "        method is to filter any uninformative columns.\n",
    "        \n",
    "        This will be selected based on index only?\n",
    "        \n",
    "        If return_x is false, it will only return the boolean mask.\n",
    "        \"\"\"\n",
    "        X = X_[X_.columns.difference(self.coef_info['excluded_cols'])]\n",
    "        \n",
    "        # order the columns correctly...\n",
    "        col_order = self.coef_info['cols'] + list([x for x in X.columns if x not in self.coef_info['cols']])\n",
    "        X = X[col_order]\n",
    "        return X\n",
    "    \n",
    "    def _redundancy(self, X):\n",
    "        _, pval_m = fisher_test(np.array(X), y)\n",
    "        col_weak = []\n",
    "        redun_cols = []\n",
    "        for idx, colname in enumerate(X.columns.tolist()):\n",
    "            if colname not in self.coef_info['weak_dep']:\n",
    "                continue\n",
    "            # determine redudundancy.\n",
    "            pvals = pval_m[idx, :]\n",
    "            redun_alpha = np.min(pvals)\n",
    "            if redun_alpha < self.relevance_alpha:\n",
    "                col_weak.append(colname)\n",
    "            else:\n",
    "                redun_cols.append(colname)\n",
    "        col_coef = [(col, coef) for col, coef in zip(X.columns.tolist(), self.coef_.flatten()) if col in col_weak]\n",
    "        self.coef_info['cols'] = [x for x, _ in col_coef]\n",
    "        self.coef_info['coef'] = [x for _, x in col_coef]\n",
    "        \n",
    "        # excl cols that are in self.coef_info['weak_dep']\n",
    "        weak_dep = [x for x in self.coef_info['weak_dep'][:] if x in col_weak]\n",
    "        self.coef_info['weak_dep'] = weak_dep[:]\n",
    "        self.coef_info['excluded_cols'] = [x for x in self.seen_cols if x not in self.coef_info['cols']]\n",
    "        self.coef_ = np.array(self.coef_info['coef']).reshape(1, -1)\n",
    "    \n",
    "    def _osfs_sel(self, X_, y):\n",
    "        \"\"\"\n",
    "        Partial fit online group feature selection method to \n",
    "        perform spectral analysis on incoming feature set\n",
    "        to then expand the coefficient listing\n",
    "        \"\"\"\n",
    "        X = np.array(X_)\n",
    "        _, pval_m = fisher_test(X, y)\n",
    "        cols_to_index = [(idx, x) for idx, x in enumerate(X_.columns) if x in self.coef_info['cols']]\n",
    "        unseen_cols_to_index = [(idx, x) for idx, x in enumerate(X_.columns) if x not in self.coef_info['cols']]\n",
    "        # get the appropriate submatrix\n",
    "        \n",
    "        col_strong = []\n",
    "        col_weak = []\n",
    "        #print(X_.columns.tolist())\n",
    "        # we will have to evaluate each feature one at a time!\n",
    "        for new_col, colname in unseen_cols_to_index:\n",
    "            new_sel = cols_to_index + col_strong + col_weak + [colname]\n",
    "            colname_to_indx = [idx for idx, x in enumerate(X_.columns.tolist()) if x in new_sel]\n",
    "            #print(colname_to_indx)\n",
    "            if len(colname_to_indx) == 1:\n",
    "                col_weak.append(colname)\n",
    "                continue\n",
    "            pval_test = pval_m[colname_to_indx, :][:, colname_to_indx]\n",
    "            try:\n",
    "                strong_dep = np.max(pval_test[np.triu_indices(pval_test.shape[0], 1)])\n",
    "                weak_dep   = np.min(pval_test[np.triu_indices(pval_test.shape[0], 1)])\n",
    "            except:\n",
    "                strong_dep = float(\"inf\")\n",
    "                weak_dep = float(\"inf\")\n",
    "            #print(strong_dep)\n",
    "            #print(weak_dep)\n",
    "            if strong_dep < self.relevance_alpha:\n",
    "                col_strong.append(colname)\n",
    "            elif weak_dep < self.relevance_alpha:\n",
    "                col_weak.append(colname)\n",
    "        \n",
    "        # now evaluate all the weak columns to determine if they are redundant or not.\n",
    "        \"\"\"\n",
    "        sel_cols = list(self.coef_info['cols']) + list(col_strong) + list(col_weak)\n",
    "        X_redun = X_[sel_cols]\n",
    "        if X_redun.shape[0] > 0:\n",
    "            _, pval_m = fisher_test(np.array(X_redun), y)\n",
    "            for idx, col in enumerate(X_redun.columns):\n",
    "                if col not in col_weak:\n",
    "                    continue\n",
    "                elif np.min(pval_m[idx, :]) < self.relevance_alpha:\n",
    "                    col_strong.append(col)\n",
    "        \"\"\"\n",
    "        # update infomation\n",
    "        #print(self.coef_info['cols'])\n",
    "        #print(col_strong)\n",
    "        self.coef_info['cols'] = list(set(self.coef_info['cols'] + col_strong + col_weak))\n",
    "        self.coef_info['strong_dep'] = list(set(self.coef_info['strong_dep'] + col_strong))\n",
    "        self.coef_info['weak_dep'] = list(set(self.coef_info['weak_dep'] + col_weak))\n",
    "        self.coef_info['excluded_cols'] = [col for col in self.seen_cols if col not in self.coef_info['cols']]        \n",
    "        \n",
    "    def fit(self, X, y, coef_init=None, intercept_init=None,\n",
    "            sample_weight=None):\n",
    "        X_ = X.copy()\n",
    "        self.seen_cols = list(set(self.seen_cols + X.columns.tolist()))\n",
    "        \n",
    "        # TODO: add the spectral selection here\n",
    "        self._osfs_sel(X, y)\n",
    "        #self.coef_info['weak_dep'] = X.columns.tolist()\n",
    "        X = self._fit_columns(X)\n",
    "        \n",
    "        super(OSFSClassifier, self).fit(X, y, coef_init=coef_init, intercept_init=intercept_init,\n",
    "            sample_weight=sample_weight)\n",
    "        self._redundancy(X)\n",
    "        return self\n",
    "    \n",
    "    def partial_fit(self, X, y, sample_weight=None):\n",
    "        X_ = X.copy()\n",
    "        self.seen_cols = list(set(self.seen_cols + X.columns.tolist()))\n",
    "        X = X[X.columns.difference(self.coef_info['excluded_cols'])]\n",
    "        #print(X.shape)\n",
    "        self._osfs_sel(X, y)\n",
    "        X = self._fit_columns(X)\n",
    "        #print(X.shape)\n",
    "        \n",
    "        # now update coefficients\n",
    "        n_samples, n_features = X.shape\n",
    "        coef_list = np.zeros(n_features, dtype=np.float64, order=\"C\")\n",
    "        coef_list[:len(self.coef_info['coef'])] = self.coef_info['coef']\n",
    "        self.coef_ = np.array(coef_list).reshape(1, -1)\n",
    "        super(OSFSClassifier, self).partial_fit(X, y, sample_weight=None)  \n",
    "        self._redundancy(X)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self._fit_columns(X, transform_only=True)\n",
    "        #print(X.shape)\n",
    "        return super(OSFSClassifier, self).predict(X)\n",
    "    def predict_proba(self, X):\n",
    "        X = self._fit_columns(X, transform_only=True)\n",
    "        #print(X.shape)\n",
    "        return super(OSFSClassifier, self).predict_proba(X)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OSFSClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
       "        n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "        relevance_alpha=0.05, shuffle=True, tol=None, verbose=0,\n",
       "        warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OSFSClassifier(max_iter=5)\n",
    "model.fit(X1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OSFSClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
       "        n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "        relevance_alpha=0.05, shuffle=True, tol=None, verbose=0,\n",
       "        warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.partial_fit(pdf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pdf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
