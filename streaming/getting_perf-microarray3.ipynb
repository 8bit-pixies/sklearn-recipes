{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from grafting_classifier import GraftingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from ogfs_classifier import OGFSClassifier\n",
    "from osfs_classifier import OSFSClassifier\n",
    "from dpp_classifier import DPPClassifier\n",
    "from dpp_classifier_mitra import DPPClassifier as DPPClassifier2\n",
    "from dpp_classifier_ogfs import DPPClassifier as DPPClassifier3\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "#import dask.dataframe as dd\n",
    "#import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['microarray\\\\colon_train.csv', 'microarray\\\\leukemia_train.csv', 'microarray\\\\lung_cancer_train.csv', 'microarray\\\\prostate_train.csv']\n"
     ]
    }
   ],
   "source": [
    "class_train = glob.glob(\"microarray/*_train.csv\")\n",
    "print(class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_label(fname):\n",
    "    targetname = fname.replace(\".csv\", \".labels\")\n",
    "    return pd.read_csv(targetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_performance(mod, fpath, mod_name):\n",
    "    train1 = pd.read_csv(fpath).fillna(0)\n",
    "    y = np.array(train_label(fpath)).flatten()\n",
    "    \n",
    "    # simulate streaming...\n",
    "    # try splitting into groups of ~10,\n",
    "    # if there is no splits, try ~5.\n",
    "    train1_cols = np.array_split(range(train1.shape[1]), int(train1.shape[1]/10.0) + 1)\n",
    "    if len(train1_cols) == 1:\n",
    "        train1_cols = np.array_split(range(train1.shape[1]), int(train1.shape[1]/5.0) + 1)\n",
    "    all_cols = []\n",
    "\n",
    "    #mod = GraftingClassifier(max_iter=5)\n",
    "    if mod_name == 'Base':\n",
    "        mod.fit(train1, y)\n",
    "        results = {'accuracy': accuracy_score(y, mod.predict(train1)), \n",
    "               'logloss': log_loss(y, mod.predict_proba(train1)), \n",
    "               'feat_dim': mod.coef_.flatten().shape}\n",
    "        return results\n",
    "    \n",
    "    # lets normalise the dataset...\n",
    "    train1 = (train1 - train1.mean())/(np.maximum(train1.std(), 1))\n",
    "    for idx, collist in enumerate(train1_cols):\n",
    "        if idx == 0:\n",
    "            column_list = list(np.array(list(train1.columns))[collist])\n",
    "            mod.fit(train1[column_list], y)\n",
    "            all_cols.extend(list(collist))\n",
    "        else:\n",
    "            all_cols.extend(list(collist))\n",
    "            column_list = list(np.array(list(train1.columns))[all_cols])\n",
    "            mod.partial_fit(train1[column_list], y)\n",
    "        \n",
    "        # debugging\n",
    "        print_cond = True if idx % int((len(train1_cols)/10)+1) == 0 else False\n",
    "        if mod_name in ['Fast_OSFS', 'DPP', 'DPP3', 'OGFS'] and print_cond:\n",
    "            print(\"\\tmodel: {}, iter: {}\".format(mod_name, idx))\n",
    "        \n",
    "        # for fast osfs\n",
    "    if mod_name == 'Fast_OSFS':\n",
    "        mod._redundancy(train1, y, mode='all')\n",
    "    \n",
    "    results = {'accuracy': accuracy_score(y, mod.predict(train1)), \n",
    "               'logloss': log_loss(y, mod.predict_proba(train1)), \n",
    "               'feat_dim': mod.coef_.flatten().shape}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_models():\n",
    "    return [\n",
    "    ('Grafting', GraftingClassifier(max_iter=5, random_state=42)), \n",
    "    #('DPP', DPPClassifier(max_iter=5, random_state=42)), \n",
    "    #('DPP2', DPPClassifier2(max_iter=5, random_state=42)),\n",
    "    #('DPP3', DPPClassifier3(max_iter=5, random_state=42)),\n",
    "    #('OGFS', OGFSClassifier(max_iter=5, random_state=42)),\n",
    "    #('OSFS', OSFSClassifier(max_iter=5, random_state=42, fast_osfs=False)),\n",
    "    ('Fast_OSFS', OSFSClassifier(max_iter=5, random_state=42)),\n",
    "    ('Base', SGDClassifier(loss='log', max_iter=5, random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex_dat = class_train[0]\n",
    "test = pd.read_csv(ex_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex_dat = class_train[0]\n",
    "print(ex_dat, pd.read_csv(ex_dat).shape)\n",
    "models = create_models()\n",
    "for nm, mod in models:\n",
    "    if nm != 'Base':\n",
    "        print(nm, get_performance(mod, ex_dat))\n",
    "    else:\n",
    "        print(nm, get_performance(mod, ex_dat, base=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex_dat = class_train[1]\n",
    "print(ex_dat, pd.read_csv(ex_dat).shape)\n",
    "models = create_models()\n",
    "for nm, mod in models:\n",
    "    print(nm, get_performance(mod, ex_dat, mod_name=nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microarray\\lung_cancer_train.csv (181, 12533)\n",
      "Grafting {'accuracy': 1.0, 'logloss': 0.00058025328079361707, 'feat_dim': (79,)}\n",
      "\tmodel: Fast_OSFS, iter: 0\n",
      "\tmodel: Fast_OSFS, iter: 126\n",
      "\tmodel: Fast_OSFS, iter: 252\n",
      "\tmodel: Fast_OSFS, iter: 378\n",
      "\tmodel: Fast_OSFS, iter: 504\n",
      "\tmodel: Fast_OSFS, iter: 630\n",
      "\tmodel: Fast_OSFS, iter: 756\n",
      "\tmodel: Fast_OSFS, iter: 882\n",
      "\tmodel: Fast_OSFS, iter: 1008\n",
      "\tmodel: Fast_OSFS, iter: 1134\n",
      "\t\t(181, 6126)\n",
      "\t\t(181, 6125)\n",
      "\t\t(181, 6124)\n",
      "\t\t(181, 6123)\n",
      "\t\t(181, 6122)\n",
      "\t\t(181, 6121)\n",
      "\t\t(181, 6120)\n",
      "\t\t(181, 6119)\n",
      "\t\t(181, 6118)\n",
      "\t\t(181, 6117)\n",
      "\t\t(181, 6116)\n",
      "\t\t(181, 6115)\n",
      "\t\t(181, 6114)\n",
      "\t\t(181, 6113)\n",
      "\t\t(181, 6112)\n",
      "\t\t(181, 6111)\n",
      "\t\t(181, 6110)\n",
      "\t\t(181, 6109)\n",
      "\t\t(181, 6108)\n",
      "\t\t(181, 6107)\n",
      "\t\t(181, 6106)\n",
      "\t\t(181, 6105)\n",
      "\t\t(181, 6104)\n",
      "\t\t(181, 6103)\n",
      "\t\t(181, 6102)\n",
      "\t\t(181, 6101)\n",
      "\t\t(181, 6100)\n",
      "\t\t(181, 6099)\n",
      "\t\t(181, 6098)\n",
      "\t\t(181, 6097)\n",
      "\t\t(181, 6096)\n",
      "\t\t(181, 6095)\n",
      "\t\t(181, 6094)\n",
      "\t\t(181, 6093)\n",
      "\t\t(181, 6092)\n",
      "\t\t(181, 6091)\n",
      "\t\t(181, 6090)\n",
      "\t\t(181, 6089)\n",
      "\t\t(181, 6088)\n",
      "\t\t(181, 6087)\n",
      "\t\t(181, 6086)\n",
      "\t\t(181, 6085)\n",
      "\t\t(181, 6084)\n",
      "\t\t(181, 6083)\n",
      "\t\t(181, 6082)\n",
      "\t\t(181, 6081)\n",
      "\t\t(181, 6080)\n",
      "\t\t(181, 6079)\n",
      "\t\t(181, 6078)\n",
      "\t\t(181, 6077)\n",
      "\t\t(181, 6076)\n",
      "\t\t(181, 6075)\n",
      "\t\t(181, 6074)\n",
      "\t\t(181, 6073)\n",
      "\t\t(181, 6072)\n",
      "\t\t(181, 6071)\n",
      "\t\t(181, 6070)\n",
      "\t\t(181, 6069)\n",
      "\t\t(181, 6068)\n",
      "\t\t(181, 6067)\n",
      "\t\t(181, 6066)\n",
      "\t\t(181, 6065)\n",
      "\t\t(181, 6064)\n",
      "\t\t(181, 6063)\n",
      "\t\t(181, 6062)\n",
      "\t\t(181, 6061)\n",
      "\t\t(181, 6060)\n",
      "\t\t(181, 6059)\n",
      "\t\t(181, 6058)\n",
      "\t\t(181, 6057)\n",
      "\t\t(181, 6056)\n",
      "\t\t(181, 6055)\n",
      "\t\t(181, 6054)\n",
      "\t\t(181, 6053)\n",
      "\t\t(181, 6052)\n",
      "\t\t(181, 6051)\n",
      "\t\t(181, 6050)\n",
      "\t\t(181, 6049)\n",
      "\t\t(181, 6048)\n",
      "\t\t(181, 6047)\n",
      "\t\t(181, 6046)\n",
      "\t\t(181, 6045)\n",
      "\t\t(181, 6044)\n",
      "\t\t(181, 6043)\n",
      "\t\t(181, 6042)\n",
      "\t\t(181, 6041)\n",
      "\t\t(181, 6040)\n",
      "\t\t(181, 6039)\n"
     ]
    }
   ],
   "source": [
    "ex_dat = class_train[2]\n",
    "print(ex_dat, pd.read_csv(ex_dat).shape)\n",
    "models = create_models()\n",
    "for nm, mod in models:\n",
    "    print(nm, get_performance(mod, ex_dat, mod_name=nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_dat = class_train[3]\n",
    "print(ex_dat, pd.read_csv(ex_dat).shape)\n",
    "models = create_models()\n",
    "for nm, mod in models:\n",
    "    print(nm, get_performance(mod, ex_dat, mod_name=nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:skrecipe]",
   "language": "python",
   "name": "conda-env-skrecipe-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
